{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "#importing train dataset\n",
    "z_train = zipfile.ZipFile('train.csv.zip')\n",
    "train = pd.read_csv(z_train.open('train.csv'), parse_dates=['Dates'], index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_binary_fields(df, field):\n",
    "    \"\"\"\n",
    "    creates new field with field name as the name of data \n",
    "    if the original data match the new field name, the data will be 1\n",
    "    if the original data does not match the new field name, the data will be 0\n",
    "    \n",
    "    returns the new field names as a list\n",
    "    \n",
    "    ex \n",
    "    make_binary_field(df, 'DayOfWeek')\n",
    "    will create new fields\n",
    "    Monday, Tuesday, Wed\n",
    "    nesday, Thursday, Friday, Saturday and Sunday\n",
    "    where\n",
    "    df['Monday'] will have value 1 for all Mondays and 0 for the rest\n",
    "    \"\"\"\n",
    "    fields = []\n",
    "    for new_field in df[field].unique():\n",
    "        df[new_field] = df[field]\n",
    "        df.loc[df[new_field] != new_field, new_field] = 0\n",
    "        df.loc[df[new_field] == new_field, new_field] = 1\n",
    "        fields.append(new_field)\n",
    "    return fields\n",
    "\n",
    "def time_trim(data):\n",
    "    data['Day'] = data['Dates'].dt.day\n",
    "    data['Month'] = data['Dates'].dt.month\n",
    "    data['Year'] = data['Dates'].dt.year\n",
    "    data['Hour'] = data['Dates'].dt.hour\n",
    "    data['Minute'] = data['Dates'].dt.minute\n",
    "    #data['DayOfWeek'] = data['Dates'].dt.dayofweek\n",
    "    data['WeekOfYear'] = data['Dates'].dt.weekofyear\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_season(df):\n",
    "    \"\"\"\n",
    "    Make new field name Season\n",
    "    and binary fields for each season\n",
    "    Has to happen after making 'Month' field\n",
    "    spring: month 2, 3, 4\n",
    "    summer: month 5, 6, 7\n",
    "    autumn: month 8, 9, 10\n",
    "    winter: month 11, 12, 1\n",
    "    \"\"\"\n",
    "    df['Season'] = df['Month']\n",
    "    df.loc[(df['Season'] > 10) | (df['Season'] == 1), 'Season'] = 'Winter'\n",
    "    df.loc[(df['Season'] > 1) & (df['Season'] <= 4), 'Season'] = 'Spring'\n",
    "    df.loc[(df['Season'] > 4) & (df['Season'] <= 7), 'Season'] = 'Summer'\n",
    "    df.loc[(df['Season'] > 7) & (df['Season'] <= 10), 'Season'] = 'Autumn'\n",
    "    seasons = make_binary_fields(df, 'Season')\n",
    "    return seasons\n",
    "\n",
    "def convert_data_to_int(df, field):\n",
    "    \"\"\"\n",
    "    Converts fields into numbers\n",
    "    \"\"\"\n",
    "    for i, f in enumerate(df[field].unique()):\n",
    "        df.loc[df[field] == f, field] = i+1\n",
    "    return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_trim(train)\n",
    "seasons = make_season(train)\n",
    "dow = make_binary_fields(train, 'DayOfWeek')\n",
    "#pdd = make_binary_fields(train, 'PdDistrict')\n",
    "#categories = make_binary_fields(train, 'Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = ['Day','Month','Year','Hour','Minute','WeekOfYear']\n",
    "#predictors.extend(pdd)\n",
    "predictors.extend(seasons)\n",
    "#predictors.extend(dow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "sfkaggle = ['ARSON','ASSAULT','BAD CHECKS','BRIBERY','BURGLARY','DISORDERLY CONDUCT',\n",
    "            'DRIVING UNDER THE INFLUENCE','DRUG/NARCOTIC','DRUNKENNESS','EMBEZZLEMENT','EXTORTION',\n",
    "            'FAMILY OFFENSES','FORGERY/COUNTERFEITING','FRAUD','GAMBLING','KIDNAPPING','LARCENY/THEFT',\n",
    "            'LIQUOR LAWS','LOITERING','MISSING PERSON','NON-CRIMINAL','OTHER OFFENSES','PORNOGRAPHY/OBSCENE MAT',\n",
    "            'PROSTITUTION','RECOVERED VEHICLE','ROBBERY','RUNAWAY','SECONDARY CODES','SEX OFFENSES FORCIBLE',\n",
    "            'SEX OFFENSES NON FORCIBLE','STOLEN PROPERTY','SUICIDE','SUSPICIOUS OCC','TREA','TRESPASS','VANDALISM',\n",
    "            'VEHICLE THEFT','WARRANTS','WEAPON LAWS']\n",
    "print sorted(train.Category.unique()) == sfkaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score(r, p):\n",
    "    \"\"\"\n",
    "    r: result\n",
    "    p: prediction from training\n",
    "\n",
    "    calculate the score as evaluated by kaggle \n",
    "\n",
    "    https://www.kaggle.com/c/sf-crime/details/evaluation\n",
    "\n",
    "    Submissions are evaluated using the multi-class logarithmic loss. \n",
    "    Each incident has been labeled with one true class. \n",
    "    For each incident, you must submit a set of predicted probabilities (one for every class). \n",
    "    The formula is then,\n",
    "\n",
    "    where N is the number of cases in the test set, \n",
    "    M is the number of class labels, \n",
    "    \\\\(log\\\\) is the natural logarithm, \n",
    "    \\\\(y_{ij}\\\\) is 1 if observation \\\\(i\\\\) is in class \\\\(j\\\\) and 0 otherwise, \n",
    "    and \\\\(p_{ij}\\\\) is the predicted probability that observation \\\\(i\\\\) belongs to class \\\\(j\\\\).\n",
    "\n",
    "    The submitted probabilities for a given incident are not required to sum to one \n",
    "    because they are rescaled prior to being scored (each row is divided by the row sum). \n",
    "    In order to avoid the extremes of the log function, \n",
    "    predicted probabilities are replaced with \\\\(max(min(p,1-10^{-15}),10^{-15})\\\\).\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "def logloss(act, pred):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/wiki/LogarithmicLoss\n",
    "    \"\"\"\n",
    "    epsilon = 1e-15\n",
    "    pred = sp.maximum(epsilon, pred)\n",
    "    pred = sp.minimum(1-epsilon, pred)\n",
    "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
    "    ll = ll * -1.0/len(act)\n",
    "    return ll\n",
    "\n",
    "def log_loss(y_true,y_pred):\n",
    "    eps = 1e-15\n",
    "    y_pred = y_pred/y_pred.sum(axis=1)[:,np.newaxis]\n",
    "    y_pred = np.maximum(eps,y_pred)\n",
    "    y_pred = np.minimum(1-eps,y_pred)\n",
    "    y_pred = np.log(y_pred)\n",
    "    ll = 0\n",
    "    for i in range(len(y_true)):\n",
    "        ll -= y_pred[i,int(y_true[i])]\n",
    "    return ll/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "enc.fit(train['Category'])\n",
    "train['CategoryEncoded'] = enc.transform(train['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = train[predictors]\n",
    "y = train['CategoryEncoded']\n",
    "xtr, xtest, ytr, ytest = cross_validation.train_test_split(x, y, test_size = 0.5, stratify = np.array(y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = LogisticRegression()\n",
    "alg.fit(xtr, ytr)\n",
    "\n",
    "prediction = alg.predict_proba(xtest)\n",
    "logloss(ytest,prediction)\n",
    "#scores = cross_validation.cross_val_score(alg, train[predictors], train[categories])\n",
    "#print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
