{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 1 \n",
    "To start, we are going to implement a linear regression set for the data. Then we will iterate, and improve, the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, we are going to attempt to use dummy variables to define new columns for more of our data. Using dummies instead of reassignment could increase precision (maybe?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_predictors = [\"Monday\", \"Tuesday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dow = {\n",
    "    \"Monday\" : 0,\n",
    "    \"Tuesday\" : 1,\n",
    "    \"Wednesday\" : 2,\n",
    "    \"Thursday\" : 3,\n",
    "    \"Friday\" : 4,\n",
    "    \"Saturday\" : 5,\n",
    "    \"Sunday\" : 6\n",
    "}\n",
    "data[\"DOW\"] = data.DayOfWeek.map(dow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is similar, but now with Police Districts so we can just deal with ints instead of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pds = {\n",
    "    \"SOUTHERN\" : 0,\n",
    "    \"MISSION\" : 1,\n",
    "    \"NORTHERN\" : 2,\n",
    "    \"BAYVIEW\" : 3,\n",
    "    \"CENTRAL\" : 4,\n",
    "    \"TERNDERLOIN\" : 5,\n",
    "    \"INGLESIDE\" : 6,\n",
    "    \"TARAVAL\" : 7,\n",
    "    \"PARK\" : 8,\n",
    "    \"RICHMOND\" : 9\n",
    "}\n",
    "data[\"pds\"] = data.PdDistrict.map(pds)\n",
    "# for crimes without PD, use \"Other\" : 10\n",
    "data[\"pds\"] = data[\"pds\"].fillna(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to use X and Y coordinates as they are pretty continuous. There are some outlying data points, so let's clean that up. First, we check for those outlying data points (which we happen to know are at the north pole)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n"
     ]
    }
   ],
   "source": [
    "for val in data.Y:\n",
    "    if val == 90.0:\n",
    "        print val\n",
    "        \n",
    "for val in data.X:\n",
    "    if val == -120.5:\n",
    "        print val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we replace those points for more reasonable numbers. Running the code below, then the code above will produce 0 outlying values (because we got rid of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.X.replace(-120.5, data[\"X\"].median(), inplace = True)\n",
    "data.Y.replace(90, data[\"Y\"].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The data cleaning train has no brakes. Now we are going to clean up date/time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_date(Dates):\n",
    "    \"\"\" Convert a date in YYYY-MM-DD HH:MM:SS to a tuple\n",
    "        containing year, month, day, and hours each expressed\n",
    "        as an integer. Used from Paul Ruvolo's example in bikeshare kaggle dataset\n",
    "\n",
    "        >>> parse_date(\"2014-04-05 14:00:00\")\n",
    "        (2014, 4, 5, 14)\n",
    "    \"\"\"\n",
    "    return int(Dates[0:4]), int(Dates[5:7]), int(Dates[8:10]), int(Dates[11:13])\n",
    "\n",
    "# \"now we use the lambda functions\" - Mack\n",
    "data[\"Year\"] = data.Dates.apply(lambda x: parse_date(x)[0])\n",
    "data[\"Month\"] = data.Dates.apply(lambda x: parse_date(x)[1])\n",
    "data[\"Hour\"] = data.Dates.apply(lambda x: parse_date(x)[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so now we are going to do the predictive thingamajig. We drew inspiration from this script (https://www.kaggle.com/sonuk7/sf-crime/prediction-with-bernoulinb/code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.19815578  0.2056471   0.08445377]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn import cross_validation\n",
    "\n",
    "cats = data.Category.values\n",
    "cleanData = data.drop([\"Address\",\"Category\",\"Dates\",\"Descript\",\"X\", \"Y\",\"Resolution\", \"DayOfWeek\", \"PdDistrict\"], axis=1)\n",
    "\n",
    "model = GaussianNB()\n",
    "# model = BernoulliNB()\n",
    "model.fit(cleanData.dropna(), cats)\n",
    "\n",
    "scores = cross_validation.cross_val_score(model, cleanData, data[\"Category\"], cv = 3)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow that's a bad score :\\ I think? Not sure really. Let's generate a test file starting with clean test data to mimic our cleaned training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8ab1451c118a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m submission = pd.DataFrame({\n\u001b[0;32m---> 39\u001b[0;31m        \u001b[0;34m\"Id\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcleanTest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m        \u001b[0;34m\"Category\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m    })\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Id'"
     ]
    }
   ],
   "source": [
    "import gzip, csv\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test[\"DOW\"] = test.DayOfWeek.map(dow)\n",
    "\n",
    "test[\"pds\"] = test.PdDistrict.map(pds)\n",
    "# for crimes without PD, use \"Other\" : 10\n",
    "test[\"pds\"] = test[\"pds\"].fillna(10)\n",
    "\n",
    "test.X.replace(-120.5, test[\"X\"].median(), inplace = True)\n",
    "test.Y.replace(90, test[\"Y\"].median(), inplace = True)\n",
    "\n",
    "test[\"Year\"] = test.Dates.apply(lambda x: parse_date(x)[0])\n",
    "test[\"Month\"] = test.Dates.apply(lambda x: parse_date(x)[1])\n",
    "test[\"Hour\"] = test.Dates.apply(lambda x: parse_date(x)[3])\n",
    "                                \n",
    "idx = test.Id.values\n",
    "\n",
    "cleanTest = test.drop([\"Id\",\"Address\",\"Dates\",\"X\", \"Y\", \"DayOfWeek\", \"PdDistrict\"], axis=1)\n",
    "\n",
    "# model = BernoulliNB()\n",
    "model = GaussianNB()\n",
    "model.fit(cleanData.dropna(), cats)\n",
    "\n",
    "predicted = model.predict_proba(cleanTest)\n",
    "#labels =  \"ARSON,ASSAULT,BAD CHECKS,BRIBERY,BURGLARY,DISORDERLY CONDUCT,DRIVING UNDER THE INFLUENCE,DRUG/NARCOTIC,DRUNKENNESS,EMBEZZLEMENT,EXTORTION,FAMILY OFFENSES,FORGERY/COUNTERFEITING,FRAUD,GAMBLING,KIDNAPPING,LARCENY/THEFT,LIQUOR LAWS,LOITERING,MISSING PERSON,NON-CRIMINAL,OTHER OFFENSES,PORNOGRAPHY/OBSCENE MAT,PROSTITUTION,RECOVERED VEHICLE,ROBBERY,RUNAWAY,SECONDARY CODES,SEX OFFENSES FORCIBLE,SEX OFFENSES NON FORCIBLE,STOLEN PROPERTY,SUICIDE,SUSPICIOUS OCC,TREA,TRESPASS,VANDALISM,VEHICLE THEFT,WARRANTS,WEAPON LAWS\".split(',')\n",
    "labels =['Id']\n",
    "for i in model.classes_:\n",
    "    labels.append(i)\n",
    "with gzip.open('bernoulinb.csv.gz', 'wb') as outf:\n",
    "    fo =csv.writer(outf, lineterminator = '\\n' )\n",
    "    fo.writerow(labels)\n",
    "    \n",
    "    for i, pred in enumerate(predicted):\n",
    "        fo.writerow([i] + list(pred))\n",
    "predictions = model.predict(cleanTest)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#        \"Id\" : cleanTest[\"Id\"],\n",
    "#        \"Category\" : predictions\n",
    "#    })\n",
    "\n",
    "# submission.to_csv(\"CYOA1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
