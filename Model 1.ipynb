{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 1 \n",
    "To start, we are going to implement a new kind of model for the data we found when exploring through the kaggle scripts: the Bernoulli Distribution. Then we will iterate, and improve, the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mackenzie/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, we are going to clean days of week to be values ranging from 0 - 6 (Mon - Sun) using a dictionary and mapping. This is another new method of replacement that so far has been pretty advantageous for changing these strings to integers/floats that can be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dow = {\n",
    "    \"Monday\" : 0,\n",
    "    \"Tuesday\" : 1,\n",
    "    \"Wednesday\" : 2,\n",
    "    \"Thursday\" : 3,\n",
    "    \"Friday\" : 4,\n",
    "    \"Saturday\" : 5,\n",
    "    \"Sunday\" : 6\n",
    "}\n",
    "data[\"DOW\"] = data.DayOfWeek.map(dow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is similar, but now with Police Districts so we can just deal with ints instead of strings. Data exploration showed these districts are good measures of district-based crime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pds = {\n",
    "    \"SOUTHERN\" : 0,\n",
    "    \"MISSION\" : 1,\n",
    "    \"NORTHERN\" : 2,\n",
    "    \"BAYVIEW\" : 3,\n",
    "    \"CENTRAL\" : 4,\n",
    "    \"TERNDERLOIN\" : 5,\n",
    "    \"INGLESIDE\" : 6,\n",
    "    \"TARAVAL\" : 7,\n",
    "    \"PARK\" : 8,\n",
    "    \"RICHMOND\" : 9\n",
    "}\n",
    "data[\"pds\"] = data.PdDistrict.map(pds)\n",
    "# for crimes without PD, use \"Other\" : 10\n",
    "data[\"pds\"] = data[\"pds\"].fillna(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to use X and Y coordinates as they are pretty continuous indicators of location (which is helpful in predicting the incident's category). There are some outlying data points, so let's clean that up. First, we check for those outlying data points (which we happen to know are at the north pole)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "90.0\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n",
      "-120.5\n"
     ]
    }
   ],
   "source": [
    "for val in data.Y:\n",
    "    if val == 90.0:\n",
    "        print val\n",
    "        \n",
    "for val in data.X:\n",
    "    if val == -120.5:\n",
    "        print val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we replace those points for more reasonable numbers. Running the code below, then the code above will produce 0 outlying values (because we got rid of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.X.replace(-120.5, data[\"X\"].median(), inplace = True)\n",
    "data.Y.replace(90, data[\"Y\"].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The data cleaning train has no brakes. Now we are going to clean up date/time. We're using year, month, and hour because our data explorations revealed there's a good chunk of dependance on crime rates throughout the years, seasonally, and at different hours of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_date(Dates):\n",
    "    \"\"\" Convert a date in YYYY-MM-DD HH:MM:SS to a tuple\n",
    "        containing year, month, day, and hours each expressed\n",
    "        as an integer. Used from Paul Ruvolo's example in bikeshare kaggle dataset\n",
    "\n",
    "        >>> parse_date(\"2014-04-05 14:00:00\")\n",
    "        (2014, 4, 5, 14)\n",
    "    \"\"\"\n",
    "    return int(Dates[0:4]), int(Dates[5:7]), int(Dates[8:10]), int(Dates[11:13])\n",
    "\n",
    "# \"now we use the lambda functions\" - Mack\n",
    "data[\"Year\"] = data.Dates.apply(lambda x: parse_date(x)[0])\n",
    "data[\"Month\"] = data.Dates.apply(lambda x: parse_date(x)[1])\n",
    "data[\"Hour\"] = data.Dates.apply(lambda x: parse_date(x)[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so now we are going to do the predictive thingamajig. We drew inspiration from this script (https://www.kaggle.com/sonuk7/sf-crime/prediction-with-bernoulinb/code ).Bernoulli distributions deal with discrete variables where we have a two-point distribution. the BernoulliNB method gives us the probability of an incident fitting a Category when the probability is trained with our input columns to be better than 50-50. We're using this because this data set deals a lot with categorical variables instead of a bunch of integers that could be continous, like in the warm-up project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.19976153  0.19864289  0.19928998]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import cross_validation\n",
    "\n",
    "cats = data.Category.values\n",
    "cleanData = data.drop([\"Address\",\"Category\",\"Dates\",\"Descript\",\"X\", \"Y\",\"Resolution\", \"DayOfWeek\", \"PdDistrict\"], axis=1)\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(cleanData.dropna(), cats)\n",
    "\n",
    "scores = cross_validation.cross_val_score(model, cleanData, data[\"Category\"], cv = 3)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow that's a bad score :\\ I think? Not sure really. Let's generate a test file starting with clean test data to mimic our cleaned training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip, csv\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test[\"DOW\"] = test.DayOfWeek.map(dow)\n",
    "\n",
    "test[\"pds\"] = test.PdDistrict.map(pds)\n",
    "# for crimes without PD, use \"Other\" : 10\n",
    "test[\"pds\"] = test[\"pds\"].fillna(10)\n",
    "\n",
    "test.X.replace(-120.5, test[\"X\"].median(), inplace = True)\n",
    "test.Y.replace(90, test[\"Y\"].median(), inplace = True)\n",
    "\n",
    "test[\"Year\"] = test.Dates.apply(lambda x: parse_date(x)[0])\n",
    "test[\"Month\"] = test.Dates.apply(lambda x: parse_date(x)[1])\n",
    "test[\"Hour\"] = test.Dates.apply(lambda x: parse_date(x)[3])\n",
    "                                \n",
    "idx = test.Id.values\n",
    "\n",
    "cleanTest = test.drop([\"Id\",\"Address\",\"Dates\",\"X\", \"Y\", \"DayOfWeek\", \"PdDistrict\"], axis=1)\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(cleanData.dropna(), cats)\n",
    "\n",
    "predicted = model.predict_proba(cleanTest)\n",
    "#labels =  \"ARSON,ASSAULT,BAD CHECKS,BRIBERY,BURGLARY,DISORDERLY CONDUCT,DRIVING UNDER THE INFLUENCE,DRUG/NARCOTIC,DRUNKENNESS,EMBEZZLEMENT,EXTORTION,FAMILY OFFENSES,FORGERY/COUNTERFEITING,FRAUD,GAMBLING,KIDNAPPING,LARCENY/THEFT,LIQUOR LAWS,LOITERING,MISSING PERSON,NON-CRIMINAL,OTHER OFFENSES,PORNOGRAPHY/OBSCENE MAT,PROSTITUTION,RECOVERED VEHICLE,ROBBERY,RUNAWAY,SECONDARY CODES,SEX OFFENSES FORCIBLE,SEX OFFENSES NON FORCIBLE,STOLEN PROPERTY,SUICIDE,SUSPICIOUS OCC,TREA,TRESPASS,VANDALISM,VEHICLE THEFT,WARRANTS,WEAPON LAWS\".split(',')\n",
    "labels =['Id']\n",
    "for i in model.classes_:\n",
    "    labels.append(i)\n",
    "with gzip.open('bernoulinb.csv.gz', 'wb') as outf:\n",
    "    fo =csv.writer(outf, lineterminator = '\\n' )\n",
    "    fo.writerow(labels)\n",
    "    \n",
    "    for i, pred in enumerate(predicted):\n",
    "        fo.writerow([i] + list(pred))\n",
    "#predictions = model.predict(cleanTest)\n",
    "\n",
    "#submission = pd.DataFrame({\n",
    "#        \"Id\" : cleanTest[\"Id\"],\n",
    "#        \"Category\" : predictions\n",
    "#    })\n",
    "\n",
    "#submission.to_csv(\"CYOA1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This submission got us a 2.66746 on our first try, yay! That means our abouve test scores were actually really good. We're bringing this to class to discuss on Tuesday. The sample submission got a 32 and is ranked at 1203 while we ranked at 818. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
