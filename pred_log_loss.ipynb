{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SF Crime Dataset asks as an interesting question. Given time and location, you must predict the category of crime that occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Dates        Category                  Descript  DayOfWeek  \\\n",
      "0 2015-05-13 23:53:00        WARRANTS            WARRANT ARREST  Wednesday   \n",
      "1 2015-05-13 23:53:00  OTHER OFFENSES  TRAFFIC VIOLATION ARREST  Wednesday   \n",
      "\n",
      "  PdDistrict      Resolution             Address           X          Y  \n",
      "0   NORTHERN  ARREST, BOOKED  OAK ST / LAGUNA ST -122.425892  37.774599  \n",
      "1   NORTHERN  ARREST, BOOKED  OAK ST / LAGUNA ST -122.425892  37.774599  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "import numpy as np\n",
    "\n",
    "# convert the Dates column of our provided data from string to datetime format.\n",
    "train=pd.read_csv('train.csv', parse_dates = ['Dates'])\n",
    "test=pd.read_csv('test.csv', parse_dates = ['Dates'])\n",
    "\n",
    "# Print the first 5 rows of the dataframe.\n",
    "print train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is providing us with several information in its columns. One of my first interests was to handle categorical data and convert them to numerical features. However, we need to make sure that the nearby resulting numerical values do not imply any form of similarity with each other, hence, we binarize our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, let's convert the crime category labels to integer values using the method LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049,)\n",
      "[37 21 21 ..., 16 35 12]\n"
     ]
    }
   ],
   "source": [
    "#Convert crime labels to numbers\n",
    "le_crime = preprocessing.LabelEncoder()\n",
    "encodedCrime = le_crime.fit_transform(train.Category)\n",
    "humanReadableCrime = le_crime.inverse_transform(encodedCrime)\n",
    "print humanReadableCrime\n",
    "print encodedCrime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create matrices that give us binarized information about the day and district certain incidents took place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get binarized weekdays and district\n",
    "days = pd.get_dummies(train.DayOfWeek)\n",
    "district = pd.get_dummies(train.PdDistrict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we handle the identification of hour in the Dates column, we can then create a new array that can be super useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gets the hour portion form the \"Dates\" column\n",
    "hour = train.Dates.dt.hour\n",
    "# Creates binarized matrix that you can access the by hour[23] to see if an incident happened at that time\n",
    "hour = pd.get_dummies(hour) \n",
    "\n",
    "#Build new array with binary info on location, day and hour and numbered crime\n",
    "train_data = pd.concat([hour, days, district], axis=1)\n",
    "train_data['crime']=crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to perform a lot of tests using our train data, we are going to further split our data into a subtrain and subtest set, respectively, while leaving the test dataset untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training, validation = train_test_split(train_data, train_size=.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we have binarize the mapping for features that include the day and district an incident happened, it would be wise to considered our primary features to be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
    " 'Wednesday', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION',\n",
    " 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make use of the Naive Baysean algorithm and calculate the log_loss; i.e. the loss function used in (multinomial) logistic regression. In addition to that, we can use logistic regression to analyze the dataset, as one or more independent variables exist that determine the outcome of the type of crime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6146195273756532"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training : 60% of training data\n",
    "# validation: 40% of training data\n",
    "\n",
    "# Naive Baysean\n",
    "model = BernoulliNB()\n",
    "model.fit(training[features], training['crime'])\n",
    "predicted = np.array(model.predict_proba(validation[features]))\n",
    "log_loss(validation['crime'], predicted) \n",
    " \n",
    "# #Logistic Regression\n",
    "# model = LogisticRegression(C=.01)\n",
    "# model.fit(training[features], training['crime'])\n",
    "# predicted = np.array(model.predict_proba(validation[features]))\n",
    "# log_loss(validation['crime'], predicted) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
