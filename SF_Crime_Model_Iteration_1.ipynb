{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SF Crime Data Model Iteration 1\n",
    "### Keenan and Joe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>PARK</td>\n",
       "      <td>NONE</td>\n",
       "      <td>100 Block of BRODERICK ST</td>\n",
       "      <td>-122.438738</td>\n",
       "      <td>37.771541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "4 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.425892  37.774599  \n",
       "1 -122.425892  37.774599  \n",
       "2 -122.424363  37.800414  \n",
       "3 -122.426995  37.800873  \n",
       "4 -122.438738  37.771541  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    " \n",
    "%matplotlib inline\n",
    "\n",
    "#Load Data with pandas, and parse the first column into datetime\n",
    "train=pd.read_csv('train.csv', parse_dates = ['Dates'])\n",
    "test=pd.read_csv('test.csv', parse_dates = ['Dates'])\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After accumulating all of the data, we begin to do some processing. The biggest challenge facing this dataset is that many of the catagories of data are not numerical, but do not have clear scales between them. Instead of just turning them into numbers, like monday 1, tuesday 2, etc, it makes more sense to binarize the data so they have the same scale. Pandas has a great function called get_dummies which does exactly that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>CENTRAL</th>\n",
       "      <th>INGLESIDE</th>\n",
       "      <th>MISSION</th>\n",
       "      <th>NORTHERN</th>\n",
       "      <th>PARK</th>\n",
       "      <th>RICHMOND</th>\n",
       "      <th>SOUTHERN</th>\n",
       "      <th>TARAVAL</th>\n",
       "      <th>TENDERLOIN</th>\n",
       "      <th>crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...    CENTRAL  INGLESIDE  MISSION  NORTHERN  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...          0          0        0         1   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...          0          0        0         1   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...          0          0        0         1   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...          0          0        0         1   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...          0          0        0         0   \n",
       "\n",
       "   PARK  RICHMOND  SOUTHERN  TARAVAL  TENDERLOIN  crime  \n",
       "0     0         0         0        0           0     37  \n",
       "1     0         0         0        0           0     21  \n",
       "2     0         0         0        0           0     21  \n",
       "3     0         0         0        0           0     16  \n",
       "4     1         0         0        0           0     16  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert crime labels to numbers\n",
    "le_crime = preprocessing.LabelEncoder()\n",
    "crime = le_crime.fit_transform(train.Category)\n",
    " \n",
    "#Get binarized weekdays, districts, and hours.\n",
    "days = pd.get_dummies(train.DayOfWeek)\n",
    "district = pd.get_dummies(train.PdDistrict)\n",
    "hour = train.Dates.dt.hour\n",
    "hour = pd.get_dummies(hour) \n",
    " \n",
    "#Build new array\n",
    "train_data = pd.concat([hour, days, district], axis=1)\n",
    "train_data['crime']=crime\n",
    " \n",
    "#Repeat for test data\n",
    "days = pd.get_dummies(test.DayOfWeek)\n",
    "district = pd.get_dummies(test.PdDistrict)\n",
    " \n",
    "hour = test.Dates.dt.hour\n",
    "hour = pd.get_dummies(hour) \n",
    " \n",
    "test_data = pd.concat([hour, days, district], axis=1)\n",
    " \n",
    "training, validation = train_test_split(train_data, train_size=.60)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to Train a Model!\n",
    "\n",
    "After doing this for both the test and train data, we can begin to test out our data. I used a Logistic Regression after splitting the training data to have validation set to work with as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.58187444573\n",
      "2.59091355533\n"
     ]
    }
   ],
   "source": [
    "features = ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
    " 'Wednesday', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION',\n",
    " 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n",
    "\n",
    "\n",
    "# Add in hours of the day into the features\n",
    "features2 = [x for x in range(0,24)]\n",
    "features = features + features2\n",
    "\n",
    "# Use the Naive Bayes model\n",
    "training, validation = train_test_split(train_data, train_size=.60)\n",
    "model = BernoulliNB()\n",
    "model.fit(training[features], training['crime'])\n",
    "predicted = np.array(model.predict_proba(validation[features]))\n",
    "print log_loss(validation['crime'], predicted) \n",
    " \n",
    "    \n",
    "    \n",
    "#Logistic Regression for comparison\n",
    "model = LogisticRegression(C=.01)\n",
    "model.fit(training[features], training['crime'])\n",
    "predicted = np.array(model.predict_proba(validation[features]))\n",
    "print log_loss(validation['crime'], predicted) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these results look pretty good, but as shown, the Naive Bayes model using the BernoulliNB model, the score was slightly better, as 2.58 is lower than 2.59, and the lower the score the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(train_data[features], train_data['crime'])\n",
    "predicted = model.predict_proba(test_data[features])\n",
    " \n",
    "#Write results\n",
    "result=pd.DataFrame(predicted, columns=le_crime.classes_)\n",
    "# result.to_csv('testResult.csv', index = True, index_label = 'Id' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I submitted this to kaggle and got a result of 2.58376, which was good enough for about 500th place out of 1250! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I learned a lot of these strategies through the tutorial at http://efavdb.com/predicting-san-francisco-crimes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New strategy --> SGDClassifier!\n",
    "\n",
    "I'm going to now try a new strategy. This is called stochastic gradient descent, which means the gradient of each loss is estimated each sample at a time and the model is updated along the way with a decreasing learning rate. How it exactly works, I have no idea, but I found it on sklearn as a good model to try, so here it goes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.58323102569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "sgd = SGDClassifier(loss='log', penalty='l2')\n",
    "sgd.fit(training[features], training['crime'])\n",
    "predicted = np.array(sgd.predict_proba(validation[features]))\n",
    "sgd_log_loss = log_loss(validation['crime'], predicted) \n",
    "\n",
    "print sgd_log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty great result! Time to make another submission to kaggle! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss='log', penalty='l2')\n",
    "model.fit(train_data[features], train_data['crime'])\n",
    "predicted = model.predict_proba(test_data[features])\n",
    "\n",
    "result=pd.DataFrame(predicted, columns=le_crime.classes_)\n",
    "result.to_csv('testResult2.csv', index = True, index_label = 'Id' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model achieved a score of: 2.58433, which was slightly lower than my previous score of 2.58376. But overall, the scores are pretty similar.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapdata = np.loadtxt(\"./sf_map_copyright_openstreetmap_contributors.txt\")\n",
    "plt.imshow(mapdata, cmap = plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# OOH! LOOK AT THE PRETTY MAP OF SAN FRANCISCO! NOICE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
