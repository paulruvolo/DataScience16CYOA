{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "\n",
    "import pandas \n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "\n",
    "#     data = pandas.read_csv('train.tsv', sep = '\\t') \n",
    "#     testdata = pandas.read_csv('test.tsv', sep = '\\t') \n",
    "    import pickle\n",
    "    f = open('rotten_tomatoes_train.pickle')\n",
    "    X = pickle.load(f)\n",
    "    y = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    # We can now download and read the training and test set images and labels.\n",
    "#     X = data.Phrase\n",
    "#     y = data.Sentiment\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=1)\n",
    "\n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    # We just return all the arrays in order, as expected in main().\n",
    "    # (It doesn't matter how we do this as long as we can read them again.)\n",
    "    \n",
    "#     vectorizer = CountVectorizer(stop_words='english')\n",
    "#     X_train = vectorizer.fit_transform([r for r in X_train])\n",
    "#     X_test = vectorizer.transform([r for r in X_test])\n",
    "#     X_val = vectorizer.transform([r for r in X_val])\n",
    "    \n",
    "    return np.asarray(X_train), np.asarray(y_train), np.asarray(X_val), np.asarray(y_val), np.asarray(X_test), np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "y_val = y_val.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03379533 -0.01067933 -0.001843    0.04078133 -0.05101033  0.04132\n",
      "  0.042465    0.01693667  0.02975167  0.06493433  0.04356933 -0.008447\n",
      " -0.004513    0.01929833 -0.05798567  0.05939867 -0.045535    0.09794233\n",
      " -0.07398533 -0.078295   -0.04083433  0.00614867  0.05273967  0.00309433\n",
      "  0.01245433 -0.00722533 -0.014074    0.05410367  0.01350467 -0.00134367\n",
      " -0.107147   -0.065084    0.03507267  0.020408    0.00586667  0.01339233\n",
      "  0.08467633  0.01912833 -0.04472767  0.067868    0.02107167 -0.04237733\n",
      "  0.045113    0.07763367 -0.023825   -0.01223167 -0.024834    0.00498233\n",
      "  0.09367567  0.01156367 -0.08171733 -0.00808033 -0.02360967  0.018158\n",
      "  0.040288   -0.05371667  0.01466867 -0.064713   -0.03671033 -0.040814\n",
      "  0.03923933  0.04472867  0.02500633  0.00970067  0.003613    0.05830767\n",
      " -0.010473   -0.00847233 -0.00520533  0.03703933  0.008759   -0.02097633\n",
      "  0.00471067 -0.00512833 -0.05676467  0.006658    0.01867967 -0.00326733\n",
      "  0.032311   -0.020348   -0.01410233  0.043098   -0.00092833 -0.06565833\n",
      "  0.00047967  0.001434   -0.06718233  0.08651167  0.02364167  0.005885\n",
      "  0.03524333  0.004489   -0.03354467  0.03900367  0.035227   -0.01296667\n",
      " -0.03787    -0.04504933 -0.04460867 -0.042109    0.010688    0.04857033\n",
      "  0.01972733 -0.01877367 -0.00769267 -0.05859333  0.036555   -0.03473633\n",
      "  0.017166   -0.00616167 -0.05178933  0.02750733  0.06654267  0.02996833\n",
      "  0.05140233  0.00339467  0.00993567 -0.01834267  0.09800467  0.012681\n",
      " -0.00375433  0.00340433  0.031305    0.014266    0.002506   -0.04163267\n",
      " -0.079575    0.04674667 -0.049769   -0.02102    -0.05614867 -0.07904467\n",
      " -0.04924333  0.05317333  0.02136567  0.03685167  0.036504   -0.044806\n",
      " -0.00143767 -0.01181133  0.04683967 -0.05641433  0.03846467  0.05696167\n",
      "  0.01623367  0.02178633  0.01328     0.07972267 -0.012432    0.055925\n",
      " -0.01074967 -0.017179   -0.014094    0.050559   -0.04505833 -0.11696633\n",
      " -0.04422467 -0.005806   -0.02329733 -0.007793    0.014686    0.04527533\n",
      " -0.00339833  0.073894   -0.04496867 -0.045811    0.06953833 -0.005795\n",
      " -0.044615   -0.00738167 -0.000988    0.01637967  0.037319   -0.017924\n",
      "  0.03228367 -0.027201    0.01757567 -0.041026   -0.00094867  0.03561267\n",
      "  0.03898367  0.050001   -0.06928967 -0.02995833  0.00640167 -0.031356\n",
      " -0.07214633 -0.010576    0.04975033  0.00728833 -0.00278667  0.040389\n",
      " -0.02004367  0.021024    0.00268867  0.01262533 -0.01157033  0.004144\n",
      " -0.05417367  0.01250033 -0.018351   -0.029192   -0.073563    0.05834633\n",
      "  0.05309967 -0.01277467 -0.03715667  0.026111   -0.04167133 -0.01416233\n",
      " -0.00113667  0.04866267 -0.03102233  0.06339567 -0.06122067  0.052525\n",
      " -0.00955833  0.03222533 -0.00996133  0.00970933 -0.01511833  0.04231833\n",
      "  0.00638367  0.05374533 -0.036474    0.05774033 -0.00248833 -0.01040467\n",
      "  0.00298267 -0.07422633  0.03167433 -0.06105367 -0.02240733  0.019343\n",
      "  0.03446867 -0.00588333  0.01463867  0.00739667  0.07652233  0.03844967\n",
      "  0.06255833 -0.02938067  0.02803233 -0.01972733  0.05616767 -0.001826\n",
      "  0.02320567  0.063315    0.003259   -0.002567   -0.02676967  0.02407133\n",
      "  0.01371     0.08106433  0.01802067 -0.066515   -0.06982967 -0.06141633\n",
      " -0.047041   -0.05963    -0.01402067 -0.00376    -0.01339033 -0.04760133\n",
      " -0.007835    0.063516    0.020055   -0.02860233 -0.05205333 -0.02314567\n",
      " -0.057132   -0.00273033  0.03191933  0.014081    0.039848   -0.02952867\n",
      "  0.02084833 -0.034791   -0.02971    -0.00056633  0.01020233 -0.05639533\n",
      "  0.05047467 -0.00415733  0.03052167 -0.03044833 -0.081476   -0.032588\n",
      " -0.01375033  0.00372233 -0.01568733  0.053063   -0.059289   -0.066119\n",
      " -0.05040033  0.00675967  0.02592167 -0.01939367  0.00165133 -0.00692333]\n",
      "[0 3 3 ..., 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "print (X_train[1,:])\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##################### Build the neural network model #######################\n",
    "# This script supports three types of models. For each one, we define a\n",
    "# function that takes a Theano variable representing the input and returns\n",
    "# the output layer of a neural network model built in Lasagne.\n",
    "\n",
    "def build_mlp(input_var=None):\n",
    "    # This creates an MLP of two hidden layers of 800 units each, followed by\n",
    "    # a softmax output layer of 10 units. It applies 20% dropout to the input\n",
    "    # data and 50% dropout to the hidden layers.\n",
    "\n",
    "    # Input layer, specifying the expected input shape of the network\n",
    "    # (unspecified batchsize, 1 channel, 28 rows and 28 columns) and\n",
    "    # linking it to the given Theano variable `input_var`, if any:\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 300),\n",
    "                                     input_var=input_var)\n",
    "\n",
    "    # Apply 20% dropout to the input data:\n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "\n",
    "    # Add a fully-connected layer of 800 units, using the linear rectifier, and\n",
    "    # initializing weights with Glorot's scheme (which is the default anyway):\n",
    "    l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in_drop, num_units=800,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "    # We'll now add dropout of 50%:\n",
    "    l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1, p=0.5)\n",
    "\n",
    "    # Another 800-unit layer:\n",
    "    l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1_drop, num_units=800,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "    # 50% dropout again:\n",
    "    l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2, p=0.5)\n",
    "\n",
    "    # Finally, we'll add the fully-connected output layer, of 5 softmax units:\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid2_drop, num_units=5,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    # Each layer is linked to its incoming layer(s), so we only need to pass\n",
    "    # the output layer to give access to a network in Lasagne:\n",
    "    return l_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ############################# Batch iterator ###############################\n",
    "# This is just a simple helper function iterating over training data in\n",
    "# mini-batches of a particular size, optionally in random order. It assumes\n",
    "# data is available as numpy arrays. For big datasets, you could load numpy\n",
    "# arrays as memory-mapped files (np.load(..., mmap_mode='r')), or write your\n",
    "# own custom data iteration function. For small datasets, you can also copy\n",
    "# them to GPU at once for slightly improved performance. This would involve\n",
    "# several changes in the main program, though, and is not demonstrated here.\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert inputs.shape[0] == len(targets)\n",
    "    print (inputs.shape[0])\n",
    "    if shuffle:\n",
    "        indices = np.arange(inputs.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, inputs.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 16.216s\n",
      "  training loss:\t\t1.314607\n",
      "  validation loss:\t\t1.266746\n",
      "  validation accuracy:\t\t51.57 %\n",
      "Epoch 2 of 500 took 14.301s\n",
      "  training loss:\t\t1.260531\n",
      "  validation loss:\t\t1.247242\n",
      "  validation accuracy:\t\t51.57 %\n",
      "Epoch 3 of 500 took 13.687s\n",
      "  training loss:\t\t1.239886\n",
      "  validation loss:\t\t1.224182\n",
      "  validation accuracy:\t\t51.57 %\n",
      "Epoch 4 of 500 took 14.322s\n",
      "  training loss:\t\t1.213231\n",
      "  validation loss:\t\t1.195559\n",
      "  validation accuracy:\t\t52.30 %\n",
      "Epoch 5 of 500 took 14.392s\n",
      "  training loss:\t\t1.185297\n",
      "  validation loss:\t\t1.170521\n",
      "  validation accuracy:\t\t53.66 %\n",
      "Epoch 6 of 500 took 14.824s\n",
      "  training loss:\t\t1.160159\n",
      "  validation loss:\t\t1.141442\n",
      "  validation accuracy:\t\t54.91 %\n",
      "Epoch 7 of 500 took 16.773s\n",
      "  training loss:\t\t1.138290\n",
      "  validation loss:\t\t1.125817\n",
      "  validation accuracy:\t\t57.07 %\n",
      "Epoch 8 of 500 took 14.897s\n",
      "  training loss:\t\t1.115625\n",
      "  validation loss:\t\t1.103561\n",
      "  validation accuracy:\t\t57.71 %\n",
      "Epoch 9 of 500 took 18.526s\n",
      "  training loss:\t\t1.094626\n",
      "  validation loss:\t\t1.075100\n",
      "  validation accuracy:\t\t58.49 %\n",
      "Epoch 10 of 500 took 15.746s\n",
      "  training loss:\t\t1.074398\n",
      "  validation loss:\t\t1.060325\n",
      "  validation accuracy:\t\t58.81 %\n",
      "Epoch 11 of 500 took 13.621s\n",
      "  training loss:\t\t1.057904\n",
      "  validation loss:\t\t1.035940\n",
      "  validation accuracy:\t\t59.07 %\n",
      "Epoch 12 of 500 took 14.340s\n",
      "  training loss:\t\t1.044582\n",
      "  validation loss:\t\t1.023577\n",
      "  validation accuracy:\t\t59.36 %\n",
      "Epoch 13 of 500 took 13.426s\n",
      "  training loss:\t\t1.033356\n",
      "  validation loss:\t\t1.015269\n",
      "  validation accuracy:\t\t59.59 %\n",
      "Epoch 14 of 500 took 14.467s\n",
      "  training loss:\t\t1.023988\n",
      "  validation loss:\t\t1.008821\n",
      "  validation accuracy:\t\t59.52 %\n",
      "Epoch 15 of 500 took 13.325s\n",
      "  training loss:\t\t1.017889\n",
      "  validation loss:\t\t0.997911\n",
      "  validation accuracy:\t\t59.59 %\n",
      "Epoch 16 of 500 took 14.990s\n",
      "  training loss:\t\t1.011004\n",
      "  validation loss:\t\t0.992303\n",
      "  validation accuracy:\t\t59.81 %\n",
      "Epoch 17 of 500 took 15.451s\n",
      "  training loss:\t\t1.007447\n",
      "  validation loss:\t\t0.995542\n",
      "  validation accuracy:\t\t59.78 %\n",
      "Epoch 18 of 500 took 16.389s\n",
      "  training loss:\t\t1.002923\n",
      "  validation loss:\t\t0.990053\n",
      "  validation accuracy:\t\t59.73 %\n",
      "Epoch 19 of 500 took 14.903s\n",
      "  training loss:\t\t0.998134\n",
      "  validation loss:\t\t0.977592\n",
      "  validation accuracy:\t\t59.82 %\n",
      "Epoch 20 of 500 took 13.479s\n",
      "  training loss:\t\t0.997405\n",
      "  validation loss:\t\t0.982392\n",
      "  validation accuracy:\t\t60.01 %\n",
      "Epoch 21 of 500 took 15.253s\n",
      "  training loss:\t\t0.993210\n",
      "  validation loss:\t\t0.981070\n",
      "  validation accuracy:\t\t60.13 %\n",
      "Epoch 22 of 500 took 13.685s\n",
      "  training loss:\t\t0.991334\n",
      "  validation loss:\t\t0.983611\n",
      "  validation accuracy:\t\t60.03 %\n",
      "Epoch 23 of 500 took 17.703s\n",
      "  training loss:\t\t0.988768\n",
      "  validation loss:\t\t0.975525\n",
      "  validation accuracy:\t\t59.91 %\n",
      "Epoch 24 of 500 took 14.030s\n",
      "  training loss:\t\t0.985036\n",
      "  validation loss:\t\t0.976692\n",
      "  validation accuracy:\t\t59.87 %\n",
      "Epoch 25 of 500 took 13.150s\n",
      "  training loss:\t\t0.983902\n",
      "  validation loss:\t\t0.981223\n",
      "  validation accuracy:\t\t59.71 %\n",
      "Epoch 26 of 500 took 13.089s\n",
      "  training loss:\t\t0.980516\n",
      "  validation loss:\t\t0.966104\n",
      "  validation accuracy:\t\t60.46 %\n",
      "Epoch 27 of 500 took 13.064s\n",
      "  training loss:\t\t0.981848\n",
      "  validation loss:\t\t0.971622\n",
      "  validation accuracy:\t\t60.28 %\n",
      "Epoch 28 of 500 took 13.247s\n",
      "  training loss:\t\t0.978898\n",
      "  validation loss:\t\t0.963144\n",
      "  validation accuracy:\t\t60.38 %\n",
      "Epoch 29 of 500 took 13.500s\n",
      "  training loss:\t\t0.977029\n",
      "  validation loss:\t\t0.967839\n",
      "  validation accuracy:\t\t60.71 %\n",
      "Epoch 30 of 500 took 13.289s\n",
      "  training loss:\t\t0.975949\n",
      "  validation loss:\t\t0.958774\n",
      "  validation accuracy:\t\t60.85 %\n",
      "Epoch 31 of 500 took 13.607s\n",
      "  training loss:\t\t0.972972\n",
      "  validation loss:\t\t0.963624\n",
      "  validation accuracy:\t\t60.87 %\n",
      "Epoch 32 of 500 took 13.263s\n",
      "  training loss:\t\t0.970689\n",
      "  validation loss:\t\t0.964638\n",
      "  validation accuracy:\t\t60.59 %\n",
      "Epoch 33 of 500 took 14.079s\n",
      "  training loss:\t\t0.971095\n",
      "  validation loss:\t\t0.950647\n",
      "  validation accuracy:\t\t60.99 %\n",
      "Epoch 34 of 500 took 19.901s\n",
      "  training loss:\t\t0.970106\n",
      "  validation loss:\t\t0.960341\n",
      "  validation accuracy:\t\t60.71 %\n",
      "Epoch 35 of 500 took 16.554s\n",
      "  training loss:\t\t0.968649\n",
      "  validation loss:\t\t0.972842\n",
      "  validation accuracy:\t\t60.51 %\n",
      "Epoch 36 of 500 took 14.037s\n",
      "  training loss:\t\t0.968972\n",
      "  validation loss:\t\t0.957513\n",
      "  validation accuracy:\t\t61.10 %\n",
      "Epoch 37 of 500 took 14.188s\n",
      "  training loss:\t\t0.966782\n",
      "  validation loss:\t\t0.956444\n",
      "  validation accuracy:\t\t60.94 %\n",
      "Epoch 38 of 500 took 13.612s\n",
      "  training loss:\t\t0.967166\n",
      "  validation loss:\t\t0.950494\n",
      "  validation accuracy:\t\t61.26 %\n",
      "Epoch 39 of 500 took 13.489s\n",
      "  training loss:\t\t0.962491\n",
      "  validation loss:\t\t0.952714\n",
      "  validation accuracy:\t\t61.16 %\n",
      "Epoch 40 of 500 took 13.689s\n",
      "  training loss:\t\t0.963484\n",
      "  validation loss:\t\t0.962949\n",
      "  validation accuracy:\t\t60.86 %\n",
      "Epoch 41 of 500 took 13.615s\n",
      "  training loss:\t\t0.963005\n",
      "  validation loss:\t\t0.952444\n",
      "  validation accuracy:\t\t61.07 %\n",
      "Epoch 42 of 500 took 16.254s\n",
      "  training loss:\t\t0.962064\n",
      "  validation loss:\t\t0.950246\n",
      "  validation accuracy:\t\t61.44 %\n",
      "Epoch 43 of 500 took 14.125s\n",
      "  training loss:\t\t0.962364\n",
      "  validation loss:\t\t0.962486\n",
      "  validation accuracy:\t\t60.81 %\n",
      "Epoch 44 of 500 took 13.308s\n",
      "  training loss:\t\t0.960443\n",
      "  validation loss:\t\t0.950200\n",
      "  validation accuracy:\t\t61.44 %\n",
      "Epoch 45 of 500 took 13.967s\n",
      "  training loss:\t\t0.959168\n",
      "  validation loss:\t\t0.945779\n",
      "  validation accuracy:\t\t61.68 %\n",
      "Epoch 46 of 500 took 13.872s\n",
      "  training loss:\t\t0.958328\n",
      "  validation loss:\t\t0.951393\n",
      "  validation accuracy:\t\t61.48 %\n",
      "Epoch 47 of 500 took 13.527s\n",
      "  training loss:\t\t0.957221\n",
      "  validation loss:\t\t0.951901\n",
      "  validation accuracy:\t\t61.20 %\n",
      "Epoch 48 of 500 took 13.393s\n",
      "  training loss:\t\t0.956923\n",
      "  validation loss:\t\t0.949462\n",
      "  validation accuracy:\t\t61.51 %\n",
      "Epoch 49 of 500 took 13.599s\n",
      "  training loss:\t\t0.957491\n",
      "  validation loss:\t\t0.951718\n",
      "  validation accuracy:\t\t61.25 %\n",
      "Epoch 50 of 500 took 15.790s\n",
      "  training loss:\t\t0.956444\n",
      "  validation loss:\t\t0.943368\n",
      "  validation accuracy:\t\t61.59 %\n",
      "Epoch 51 of 500 took 13.163s\n",
      "  training loss:\t\t0.953872\n",
      "  validation loss:\t\t0.947017\n",
      "  validation accuracy:\t\t61.62 %\n",
      "Epoch 52 of 500 took 13.056s\n",
      "  training loss:\t\t0.952841\n",
      "  validation loss:\t\t0.954393\n",
      "  validation accuracy:\t\t60.97 %\n",
      "Epoch 53 of 500 took 15.990s\n",
      "  training loss:\t\t0.950947\n",
      "  validation loss:\t\t0.952374\n",
      "  validation accuracy:\t\t61.15 %\n",
      "Epoch 54 of 500 took 15.310s\n",
      "  training loss:\t\t0.953007\n",
      "  validation loss:\t\t0.954015\n",
      "  validation accuracy:\t\t61.16 %\n",
      "Epoch 55 of 500 took 15.464s\n",
      "  training loss:\t\t0.952835\n",
      "  validation loss:\t\t0.950238\n",
      "  validation accuracy:\t\t61.36 %\n",
      "Epoch 56 of 500 took 15.005s\n",
      "  training loss:\t\t0.949831\n",
      "  validation loss:\t\t0.943968\n",
      "  validation accuracy:\t\t61.62 %\n",
      "Epoch 57 of 500 took 18.384s\n",
      "  training loss:\t\t0.950003\n",
      "  validation loss:\t\t0.941918\n",
      "  validation accuracy:\t\t61.80 %\n",
      "Epoch 58 of 500 took 13.949s\n",
      "  training loss:\t\t0.949395\n",
      "  validation loss:\t\t0.957291\n",
      "  validation accuracy:\t\t60.87 %\n",
      "Epoch 59 of 500 took 13.126s\n",
      "  training loss:\t\t0.950082\n",
      "  validation loss:\t\t0.948428\n",
      "  validation accuracy:\t\t61.28 %\n",
      "Epoch 60 of 500 took 13.060s\n",
      "  training loss:\t\t0.948515\n",
      "  validation loss:\t\t0.944088\n",
      "  validation accuracy:\t\t61.50 %\n",
      "Epoch 61 of 500 took 13.240s\n",
      "  training loss:\t\t0.948732\n",
      "  validation loss:\t\t0.944699\n",
      "  validation accuracy:\t\t61.50 %\n",
      "Epoch 62 of 500 took 13.466s\n",
      "  training loss:\t\t0.946268\n",
      "  validation loss:\t\t0.942041\n",
      "  validation accuracy:\t\t61.77 %\n",
      "Epoch 63 of 500 took 13.368s\n",
      "  training loss:\t\t0.946955\n",
      "  validation loss:\t\t0.938353\n",
      "  validation accuracy:\t\t61.83 %\n",
      "Epoch 64 of 500 took 13.959s\n",
      "  training loss:\t\t0.943997\n",
      "  validation loss:\t\t0.938578\n",
      "  validation accuracy:\t\t61.84 %\n",
      "Epoch 65 of 500 took 13.950s\n",
      "  training loss:\t\t0.945445\n",
      "  validation loss:\t\t0.940624\n",
      "  validation accuracy:\t\t61.85 %\n",
      "Epoch 66 of 500 took 14.590s\n",
      "  training loss:\t\t0.944147\n",
      "  validation loss:\t\t0.934993\n",
      "  validation accuracy:\t\t62.01 %\n",
      "Epoch 67 of 500 took 13.960s\n",
      "  training loss:\t\t0.943276\n",
      "  validation loss:\t\t0.939914\n",
      "  validation accuracy:\t\t61.86 %\n",
      "Epoch 68 of 500 took 13.636s\n",
      "  training loss:\t\t0.943920\n",
      "  validation loss:\t\t0.941697\n",
      "  validation accuracy:\t\t61.72 %\n",
      "Epoch 69 of 500 took 13.370s\n",
      "  training loss:\t\t0.942055\n",
      "  validation loss:\t\t0.942158\n",
      "  validation accuracy:\t\t61.87 %\n",
      "Epoch 70 of 500 took 13.071s\n",
      "  training loss:\t\t0.940814\n",
      "  validation loss:\t\t0.942920\n",
      "  validation accuracy:\t\t61.67 %\n",
      "Epoch 71 of 500 took 13.063s\n",
      "  training loss:\t\t0.941416\n",
      "  validation loss:\t\t0.932324\n",
      "  validation accuracy:\t\t62.10 %\n",
      "Epoch 72 of 500 took 13.075s\n",
      "  training loss:\t\t0.940289\n",
      "  validation loss:\t\t0.938700\n",
      "  validation accuracy:\t\t61.85 %\n",
      "Epoch 73 of 500 took 13.680s\n",
      "  training loss:\t\t0.939955\n",
      "  validation loss:\t\t0.944330\n",
      "  validation accuracy:\t\t61.16 %\n",
      "Epoch 74 of 500 took 13.158s\n",
      "  training loss:\t\t0.939981\n",
      "  validation loss:\t\t0.939058\n",
      "  validation accuracy:\t\t62.05 %\n",
      "Epoch 75 of 500 took 15.232s\n",
      "  training loss:\t\t0.938750\n",
      "  validation loss:\t\t0.939350\n",
      "  validation accuracy:\t\t61.70 %\n",
      "Epoch 76 of 500 took 13.664s\n",
      "  training loss:\t\t0.937790\n",
      "  validation loss:\t\t0.931415\n",
      "  validation accuracy:\t\t62.08 %\n",
      "Epoch 77 of 500 took 13.648s\n",
      "  training loss:\t\t0.937611\n",
      "  validation loss:\t\t0.935017\n",
      "  validation accuracy:\t\t62.17 %\n",
      "Epoch 78 of 500 took 13.489s\n",
      "  training loss:\t\t0.938557\n",
      "  validation loss:\t\t0.945409\n",
      "  validation accuracy:\t\t61.50 %\n",
      "Epoch 79 of 500 took 13.694s\n",
      "  training loss:\t\t0.935872\n",
      "  validation loss:\t\t0.934742\n",
      "  validation accuracy:\t\t61.84 %\n",
      "Epoch 80 of 500 took 13.495s\n",
      "  training loss:\t\t0.937674\n",
      "  validation loss:\t\t0.935466\n",
      "  validation accuracy:\t\t61.99 %\n",
      "Epoch 81 of 500 took 14.412s\n",
      "  training loss:\t\t0.935423\n",
      "  validation loss:\t\t0.932350\n",
      "  validation accuracy:\t\t61.93 %\n",
      "Epoch 82 of 500 took 17.144s\n",
      "  training loss:\t\t0.934297\n",
      "  validation loss:\t\t0.940735\n",
      "  validation accuracy:\t\t61.56 %\n",
      "Epoch 83 of 500 took 14.669s\n",
      "  training loss:\t\t0.933852\n",
      "  validation loss:\t\t0.928521\n",
      "  validation accuracy:\t\t62.02 %\n",
      "Epoch 84 of 500 took 13.989s\n",
      "  training loss:\t\t0.933233\n",
      "  validation loss:\t\t0.936311\n",
      "  validation accuracy:\t\t61.80 %\n",
      "Epoch 85 of 500 took 13.469s\n",
      "  training loss:\t\t0.934053\n",
      "  validation loss:\t\t0.926931\n",
      "  validation accuracy:\t\t62.17 %\n",
      "Epoch 86 of 500 took 14.106s\n",
      "  training loss:\t\t0.932869\n",
      "  validation loss:\t\t0.936957\n",
      "  validation accuracy:\t\t62.12 %\n",
      "Epoch 87 of 500 took 13.511s\n",
      "  training loss:\t\t0.931955\n",
      "  validation loss:\t\t0.936720\n",
      "  validation accuracy:\t\t62.00 %\n",
      "Epoch 88 of 500 took 15.115s\n",
      "  training loss:\t\t0.931154\n",
      "  validation loss:\t\t0.938496\n",
      "  validation accuracy:\t\t61.53 %\n",
      "Epoch 89 of 500 took 18.557s\n",
      "  training loss:\t\t0.932684\n",
      "  validation loss:\t\t0.933574\n",
      "  validation accuracy:\t\t61.78 %\n",
      "Epoch 90 of 500 took 14.501s\n",
      "  training loss:\t\t0.930762\n",
      "  validation loss:\t\t0.936409\n",
      "  validation accuracy:\t\t61.77 %\n",
      "Epoch 91 of 500 took 13.776s\n",
      "  training loss:\t\t0.930249\n",
      "  validation loss:\t\t0.930723\n",
      "  validation accuracy:\t\t62.09 %\n",
      "Epoch 92 of 500 took 15.029s\n",
      "  training loss:\t\t0.930072\n",
      "  validation loss:\t\t0.947297\n",
      "  validation accuracy:\t\t61.10 %\n",
      "Epoch 93 of 500 took 14.131s\n",
      "  training loss:\t\t0.929327\n",
      "  validation loss:\t\t0.951811\n",
      "  validation accuracy:\t\t60.76 %\n",
      "Epoch 94 of 500 took 14.149s\n",
      "  training loss:\t\t0.929971\n",
      "  validation loss:\t\t0.928074\n",
      "  validation accuracy:\t\t62.07 %\n",
      "Epoch 95 of 500 took 14.132s\n",
      "  training loss:\t\t0.927886\n",
      "  validation loss:\t\t0.928860\n",
      "  validation accuracy:\t\t61.94 %\n",
      "Epoch 96 of 500 took 13.828s\n",
      "  training loss:\t\t0.927324\n",
      "  validation loss:\t\t0.931355\n",
      "  validation accuracy:\t\t62.26 %\n",
      "Epoch 97 of 500 took 14.990s\n",
      "  training loss:\t\t0.926540\n",
      "  validation loss:\t\t0.931033\n",
      "  validation accuracy:\t\t62.19 %\n",
      "Epoch 98 of 500 took 13.425s\n",
      "  training loss:\t\t0.925788\n",
      "  validation loss:\t\t0.932233\n",
      "  validation accuracy:\t\t61.97 %\n",
      "Epoch 99 of 500 took 13.848s\n",
      "  training loss:\t\t0.927538\n",
      "  validation loss:\t\t0.925244\n",
      "  validation accuracy:\t\t62.28 %\n",
      "Epoch 100 of 500 took 13.354s\n",
      "  training loss:\t\t0.926497\n",
      "  validation loss:\t\t0.945230\n",
      "  validation accuracy:\t\t61.00 %\n",
      "Epoch 101 of 500 took 13.591s\n",
      "  training loss:\t\t0.923470\n",
      "  validation loss:\t\t0.927368\n",
      "  validation accuracy:\t\t62.23 %\n",
      "Epoch 102 of 500 took 14.103s\n",
      "  training loss:\t\t0.923177\n",
      "  validation loss:\t\t0.930156\n",
      "  validation accuracy:\t\t62.22 %\n",
      "Epoch 103 of 500 took 17.479s\n",
      "  training loss:\t\t0.923287\n",
      "  validation loss:\t\t0.921793\n",
      "  validation accuracy:\t\t62.60 %\n",
      "Epoch 104 of 500 took 14.009s\n",
      "  training loss:\t\t0.922864\n",
      "  validation loss:\t\t0.922287\n",
      "  validation accuracy:\t\t62.70 %\n",
      "Epoch 105 of 500 took 13.233s\n",
      "  training loss:\t\t0.923452\n",
      "  validation loss:\t\t0.929349\n",
      "  validation accuracy:\t\t62.18 %\n",
      "Epoch 106 of 500 took 13.570s\n",
      "  training loss:\t\t0.921464\n",
      "  validation loss:\t\t0.918939\n",
      "  validation accuracy:\t\t62.67 %\n",
      "Epoch 107 of 500 took 13.916s\n",
      "  training loss:\t\t0.920724\n",
      "  validation loss:\t\t0.924122\n",
      "  validation accuracy:\t\t62.33 %\n",
      "Epoch 108 of 500 took 13.544s\n",
      "  training loss:\t\t0.922487\n",
      "  validation loss:\t\t0.922808\n",
      "  validation accuracy:\t\t62.66 %\n",
      "Epoch 109 of 500 took 13.620s\n",
      "  training loss:\t\t0.919596\n",
      "  validation loss:\t\t0.919536\n",
      "  validation accuracy:\t\t62.39 %\n",
      "Epoch 110 of 500 took 13.823s\n",
      "  training loss:\t\t0.919900\n",
      "  validation loss:\t\t0.924585\n",
      "  validation accuracy:\t\t62.52 %\n",
      "Epoch 111 of 500 took 13.874s\n",
      "  training loss:\t\t0.920090\n",
      "  validation loss:\t\t0.925063\n",
      "  validation accuracy:\t\t62.20 %\n",
      "Epoch 112 of 500 took 13.654s\n",
      "  training loss:\t\t0.919617\n",
      "  validation loss:\t\t0.924322\n",
      "  validation accuracy:\t\t62.36 %\n",
      "Epoch 113 of 500 took 13.494s\n",
      "  training loss:\t\t0.916101\n",
      "  validation loss:\t\t0.928978\n",
      "  validation accuracy:\t\t62.24 %\n",
      "Epoch 114 of 500 took 13.551s\n",
      "  training loss:\t\t0.918404\n",
      "  validation loss:\t\t0.937037\n",
      "  validation accuracy:\t\t61.71 %\n",
      "Epoch 115 of 500 took 13.358s\n",
      "  training loss:\t\t0.917355\n",
      "  validation loss:\t\t0.925319\n",
      "  validation accuracy:\t\t62.12 %\n",
      "Epoch 116 of 500 took 13.429s\n",
      "  training loss:\t\t0.916649\n",
      "  validation loss:\t\t0.919511\n",
      "  validation accuracy:\t\t62.54 %\n",
      "Epoch 117 of 500 took 13.285s\n",
      "  training loss:\t\t0.916057\n",
      "  validation loss:\t\t0.933109\n",
      "  validation accuracy:\t\t62.06 %\n",
      "Epoch 118 of 500 took 13.113s\n",
      "  training loss:\t\t0.917017\n",
      "  validation loss:\t\t0.929025\n",
      "  validation accuracy:\t\t61.95 %\n",
      "Epoch 119 of 500 took 13.057s\n",
      "  training loss:\t\t0.912778\n",
      "  validation loss:\t\t0.920166\n",
      "  validation accuracy:\t\t62.62 %\n",
      "Epoch 120 of 500 took 13.076s\n",
      "  training loss:\t\t0.914110\n",
      "  validation loss:\t\t0.922219\n",
      "  validation accuracy:\t\t62.41 %\n",
      "Epoch 121 of 500 took 13.049s\n",
      "  training loss:\t\t0.915329\n",
      "  validation loss:\t\t0.919632\n",
      "  validation accuracy:\t\t62.18 %\n",
      "Epoch 122 of 500 took 13.597s\n",
      "  training loss:\t\t0.915162\n",
      "  validation loss:\t\t0.929186\n",
      "  validation accuracy:\t\t62.05 %\n",
      "Epoch 123 of 500 took 13.041s\n",
      "  training loss:\t\t0.915578\n",
      "  validation loss:\t\t0.934467\n",
      "  validation accuracy:\t\t61.53 %\n",
      "Epoch 124 of 500 took 13.065s\n",
      "  training loss:\t\t0.913082\n",
      "  validation loss:\t\t0.924840\n",
      "  validation accuracy:\t\t62.25 %\n",
      "Epoch 125 of 500 took 13.051s\n",
      "  training loss:\t\t0.913361\n",
      "  validation loss:\t\t0.924680\n",
      "  validation accuracy:\t\t62.31 %\n",
      "Epoch 126 of 500 took 13.062s\n",
      "  training loss:\t\t0.913399\n",
      "  validation loss:\t\t0.919840\n",
      "  validation accuracy:\t\t62.59 %\n",
      "Epoch 127 of 500 took 13.048s\n",
      "  training loss:\t\t0.911230\n",
      "  validation loss:\t\t0.923069\n",
      "  validation accuracy:\t\t62.53 %\n",
      "Epoch 128 of 500 took 13.931s\n",
      "  training loss:\t\t0.913413\n",
      "  validation loss:\t\t0.928277\n",
      "  validation accuracy:\t\t62.01 %\n",
      "Epoch 129 of 500 took 13.082s\n",
      "  training loss:\t\t0.910945\n",
      "  validation loss:\t\t0.927386\n",
      "  validation accuracy:\t\t62.31 %\n",
      "Epoch 130 of 500 took 13.066s\n",
      "  training loss:\t\t0.911240\n",
      "  validation loss:\t\t0.921950\n",
      "  validation accuracy:\t\t62.34 %\n",
      "Epoch 131 of 500 took 13.109s\n",
      "  training loss:\t\t0.909496\n",
      "  validation loss:\t\t0.926690\n",
      "  validation accuracy:\t\t62.36 %\n",
      "Epoch 132 of 500 took 13.100s\n",
      "  training loss:\t\t0.912185\n",
      "  validation loss:\t\t0.926109\n",
      "  validation accuracy:\t\t62.11 %\n",
      "Epoch 133 of 500 took 13.074s\n",
      "  training loss:\t\t0.909302\n",
      "  validation loss:\t\t0.926384\n",
      "  validation accuracy:\t\t62.05 %\n",
      "Epoch 134 of 500 took 13.074s\n",
      "  training loss:\t\t0.910666\n",
      "  validation loss:\t\t0.915537\n",
      "  validation accuracy:\t\t62.81 %\n",
      "Epoch 135 of 500 took 13.330s\n",
      "  training loss:\t\t0.909222\n",
      "  validation loss:\t\t0.926300\n",
      "  validation accuracy:\t\t61.97 %\n",
      "Epoch 136 of 500 took 13.086s\n",
      "  training loss:\t\t0.907485\n",
      "  validation loss:\t\t0.924084\n",
      "  validation accuracy:\t\t62.07 %\n",
      "Epoch 137 of 500 took 13.378s\n",
      "  training loss:\t\t0.906041\n",
      "  validation loss:\t\t0.935159\n",
      "  validation accuracy:\t\t61.60 %\n",
      "Epoch 138 of 500 took 13.095s\n",
      "  training loss:\t\t0.907515\n",
      "  validation loss:\t\t0.930515\n",
      "  validation accuracy:\t\t61.97 %\n",
      "Epoch 139 of 500 took 13.080s\n",
      "  training loss:\t\t0.906644\n",
      "  validation loss:\t\t0.919688\n",
      "  validation accuracy:\t\t62.73 %\n",
      "Epoch 140 of 500 took 13.047s\n",
      "  training loss:\t\t0.906627\n",
      "  validation loss:\t\t0.927490\n",
      "  validation accuracy:\t\t62.01 %\n",
      "Epoch 141 of 500 took 13.086s\n",
      "  training loss:\t\t0.906545\n",
      "  validation loss:\t\t0.922786\n",
      "  validation accuracy:\t\t62.27 %\n",
      "Epoch 142 of 500 took 13.385s\n",
      "  training loss:\t\t0.904507\n",
      "  validation loss:\t\t0.931015\n",
      "  validation accuracy:\t\t61.84 %\n",
      "Epoch 143 of 500 took 13.142s\n",
      "  training loss:\t\t0.904872\n",
      "  validation loss:\t\t0.921285\n",
      "  validation accuracy:\t\t62.42 %\n",
      "Epoch 144 of 500 took 13.025s\n",
      "  training loss:\t\t0.903413\n",
      "  validation loss:\t\t0.914026\n",
      "  validation accuracy:\t\t62.68 %\n",
      "Epoch 145 of 500 took 13.045s\n",
      "  training loss:\t\t0.903478\n",
      "  validation loss:\t\t0.915062\n",
      "  validation accuracy:\t\t62.75 %\n",
      "Epoch 146 of 500 took 13.033s\n",
      "  training loss:\t\t0.905184\n",
      "  validation loss:\t\t0.919035\n",
      "  validation accuracy:\t\t62.44 %\n",
      "Epoch 147 of 500 took 13.081s\n",
      "  training loss:\t\t0.902290\n",
      "  validation loss:\t\t0.918196\n",
      "  validation accuracy:\t\t62.68 %\n",
      "Epoch 148 of 500 took 13.048s\n",
      "  training loss:\t\t0.903986\n",
      "  validation loss:\t\t0.917113\n",
      "  validation accuracy:\t\t62.58 %\n",
      "Epoch 149 of 500 took 13.069s\n",
      "  training loss:\t\t0.900577\n",
      "  validation loss:\t\t0.918379\n",
      "  validation accuracy:\t\t62.43 %\n",
      "Epoch 150 of 500 took 13.056s\n",
      "  training loss:\t\t0.902233\n",
      "  validation loss:\t\t0.918121\n",
      "  validation accuracy:\t\t62.42 %\n",
      "Epoch 151 of 500 took 13.042s\n",
      "  training loss:\t\t0.901963\n",
      "  validation loss:\t\t0.922446\n",
      "  validation accuracy:\t\t62.16 %\n",
      "Epoch 152 of 500 took 13.052s\n",
      "  training loss:\t\t0.900949\n",
      "  validation loss:\t\t0.918705\n",
      "  validation accuracy:\t\t62.40 %\n",
      "Epoch 153 of 500 took 13.041s\n",
      "  training loss:\t\t0.900918\n",
      "  validation loss:\t\t0.926778\n",
      "  validation accuracy:\t\t62.21 %\n",
      "Epoch 154 of 500 took 13.767s\n",
      "  training loss:\t\t0.901319\n",
      "  validation loss:\t\t0.919506\n",
      "  validation accuracy:\t\t62.32 %\n",
      "Epoch 155 of 500 took 13.141s\n",
      "  training loss:\t\t0.898789\n",
      "  validation loss:\t\t0.930967\n",
      "  validation accuracy:\t\t61.77 %\n",
      "Epoch 156 of 500 took 13.060s\n",
      "  training loss:\t\t0.899178\n",
      "  validation loss:\t\t0.910452\n",
      "  validation accuracy:\t\t63.04 %\n",
      "Epoch 157 of 500 took 13.028s\n",
      "  training loss:\t\t0.899162\n",
      "  validation loss:\t\t0.914903\n",
      "  validation accuracy:\t\t62.64 %\n",
      "Epoch 158 of 500 took 13.327s\n",
      "  training loss:\t\t0.900141\n",
      "  validation loss:\t\t0.923540\n",
      "  validation accuracy:\t\t62.13 %\n",
      "Epoch 159 of 500 took 13.071s\n",
      "  training loss:\t\t0.899434\n",
      "  validation loss:\t\t0.916284\n",
      "  validation accuracy:\t\t62.47 %\n",
      "Epoch 160 of 500 took 13.061s\n",
      "  training loss:\t\t0.897229\n",
      "  validation loss:\t\t0.926721\n",
      "  validation accuracy:\t\t61.88 %\n",
      "Epoch 161 of 500 took 13.060s\n",
      "  training loss:\t\t0.896572\n",
      "  validation loss:\t\t0.914686\n",
      "  validation accuracy:\t\t62.62 %\n",
      "Epoch 162 of 500 took 13.064s\n",
      "  training loss:\t\t0.895341\n",
      "  validation loss:\t\t0.920687\n",
      "  validation accuracy:\t\t62.09 %\n",
      "Epoch 163 of 500 took 13.069s\n",
      "  training loss:\t\t0.896129\n",
      "  validation loss:\t\t0.910892\n",
      "  validation accuracy:\t\t62.94 %\n",
      "Epoch 164 of 500 took 13.077s\n",
      "  training loss:\t\t0.895149\n",
      "  validation loss:\t\t0.915755\n",
      "  validation accuracy:\t\t62.49 %\n",
      "Epoch 165 of 500 took 13.055s\n",
      "  training loss:\t\t0.895277\n",
      "  validation loss:\t\t0.922843\n",
      "  validation accuracy:\t\t62.23 %\n",
      "Epoch 166 of 500 took 13.033s\n",
      "  training loss:\t\t0.892801\n",
      "  validation loss:\t\t0.912618\n",
      "  validation accuracy:\t\t62.87 %\n",
      "Epoch 167 of 500 took 13.037s\n",
      "  training loss:\t\t0.894580\n",
      "  validation loss:\t\t0.921237\n",
      "  validation accuracy:\t\t62.29 %\n",
      "Epoch 168 of 500 took 13.044s\n",
      "  training loss:\t\t0.894129\n",
      "  validation loss:\t\t0.910807\n",
      "  validation accuracy:\t\t62.82 %\n",
      "Epoch 169 of 500 took 13.041s\n",
      "  training loss:\t\t0.894375\n",
      "  validation loss:\t\t0.909320\n",
      "  validation accuracy:\t\t62.94 %\n",
      "Epoch 170 of 500 took 13.036s\n",
      "  training loss:\t\t0.893103\n",
      "  validation loss:\t\t0.916885\n",
      "  validation accuracy:\t\t62.70 %\n",
      "Epoch 171 of 500 took 13.040s\n",
      "  training loss:\t\t0.891808\n",
      "  validation loss:\t\t0.914595\n",
      "  validation accuracy:\t\t62.60 %\n",
      "Epoch 172 of 500 took 13.030s\n",
      "  training loss:\t\t0.892721\n",
      "  validation loss:\t\t0.909826\n",
      "  validation accuracy:\t\t62.94 %\n",
      "Epoch 173 of 500 took 14.359s\n",
      "  training loss:\t\t0.890785\n",
      "  validation loss:\t\t0.917582\n",
      "  validation accuracy:\t\t62.33 %\n",
      "Epoch 174 of 500 took 13.041s\n",
      "  training loss:\t\t0.891377\n",
      "  validation loss:\t\t0.914042\n",
      "  validation accuracy:\t\t62.77 %\n",
      "Epoch 175 of 500 took 13.033s\n",
      "  training loss:\t\t0.890828\n",
      "  validation loss:\t\t0.911220\n",
      "  validation accuracy:\t\t62.67 %\n",
      "Epoch 176 of 500 took 13.576s\n",
      "  training loss:\t\t0.890571\n",
      "  validation loss:\t\t0.928094\n",
      "  validation accuracy:\t\t62.00 %\n",
      "Epoch 177 of 500 took 14.778s\n",
      "  training loss:\t\t0.889176\n",
      "  validation loss:\t\t0.918746\n",
      "  validation accuracy:\t\t62.58 %\n",
      "Epoch 178 of 500 took 14.564s\n",
      "  training loss:\t\t0.888842\n",
      "  validation loss:\t\t0.915330\n",
      "  validation accuracy:\t\t62.46 %\n",
      "Epoch 179 of 500 took 13.716s\n",
      "  training loss:\t\t0.889239\n",
      "  validation loss:\t\t0.916766\n",
      "  validation accuracy:\t\t62.54 %\n",
      "Epoch 180 of 500 took 16.262s\n",
      "  training loss:\t\t0.887818\n",
      "  validation loss:\t\t0.905433\n",
      "  validation accuracy:\t\t63.28 %\n",
      "Epoch 181 of 500 took 16.700s\n",
      "  training loss:\t\t0.887203\n",
      "  validation loss:\t\t0.916302\n",
      "  validation accuracy:\t\t62.31 %\n",
      "Epoch 182 of 500 took 13.024s\n",
      "  training loss:\t\t0.888984\n",
      "  validation loss:\t\t0.913481\n",
      "  validation accuracy:\t\t62.78 %\n",
      "Epoch 183 of 500 took 13.029s\n",
      "  training loss:\t\t0.887486\n",
      "  validation loss:\t\t0.917006\n",
      "  validation accuracy:\t\t62.45 %\n",
      "Epoch 184 of 500 took 14.667s\n",
      "  training loss:\t\t0.884824\n",
      "  validation loss:\t\t0.913524\n",
      "  validation accuracy:\t\t62.50 %\n",
      "Epoch 185 of 500 took 13.024s\n",
      "  training loss:\t\t0.885644\n",
      "  validation loss:\t\t0.911840\n",
      "  validation accuracy:\t\t62.57 %\n",
      "Epoch 186 of 500 took 16.226s\n",
      "  training loss:\t\t0.885445\n",
      "  validation loss:\t\t0.910788\n",
      "  validation accuracy:\t\t62.85 %\n",
      "Epoch 187 of 500 took 16.972s\n",
      "  training loss:\t\t0.884801\n",
      "  validation loss:\t\t0.910853\n",
      "  validation accuracy:\t\t62.62 %\n",
      "Epoch 188 of 500 took 14.908s\n",
      "  training loss:\t\t0.885369\n",
      "  validation loss:\t\t0.911376\n",
      "  validation accuracy:\t\t63.14 %\n",
      "Epoch 189 of 500 took 14.556s\n",
      "  training loss:\t\t0.884053\n",
      "  validation loss:\t\t0.911483\n",
      "  validation accuracy:\t\t62.71 %\n",
      "Epoch 190 of 500 took 15.017s\n",
      "  training loss:\t\t0.885259\n",
      "  validation loss:\t\t0.907637\n",
      "  validation accuracy:\t\t62.73 %\n",
      "Epoch 191 of 500 took 14.695s\n",
      "  training loss:\t\t0.885427\n",
      "  validation loss:\t\t0.902710\n",
      "  validation accuracy:\t\t63.07 %\n",
      "Epoch 192 of 500 took 15.016s\n",
      "  training loss:\t\t0.882229\n",
      "  validation loss:\t\t0.910802\n",
      "  validation accuracy:\t\t63.21 %\n",
      "Epoch 193 of 500 took 15.458s\n",
      "  training loss:\t\t0.881646\n",
      "  validation loss:\t\t0.916666\n",
      "  validation accuracy:\t\t62.73 %\n",
      "Epoch 194 of 500 took 17.260s\n",
      "  training loss:\t\t0.883767\n",
      "  validation loss:\t\t0.915317\n",
      "  validation accuracy:\t\t62.65 %\n",
      "Epoch 195 of 500 took 19.224s\n",
      "  training loss:\t\t0.882547\n",
      "  validation loss:\t\t0.904964\n",
      "  validation accuracy:\t\t63.12 %\n",
      "Epoch 196 of 500 took 13.729s\n",
      "  training loss:\t\t0.882353\n",
      "  validation loss:\t\t0.912586\n",
      "  validation accuracy:\t\t62.42 %\n",
      "Epoch 197 of 500 took 13.148s\n",
      "  training loss:\t\t0.882553\n",
      "  validation loss:\t\t0.911204\n",
      "  validation accuracy:\t\t63.01 %\n",
      "Epoch 198 of 500 took 13.096s\n",
      "  training loss:\t\t0.884005\n",
      "  validation loss:\t\t0.909683\n",
      "  validation accuracy:\t\t63.14 %\n",
      "Epoch 199 of 500 took 13.674s\n",
      "  training loss:\t\t0.881158\n",
      "  validation loss:\t\t0.911714\n",
      "  validation accuracy:\t\t62.97 %\n",
      "Epoch 200 of 500 took 14.691s\n",
      "  training loss:\t\t0.879359\n",
      "  validation loss:\t\t0.915534\n",
      "  validation accuracy:\t\t62.57 %\n",
      "Epoch 201 of 500 took 17.191s\n",
      "  training loss:\t\t0.881766\n",
      "  validation loss:\t\t0.912520\n",
      "  validation accuracy:\t\t62.56 %\n",
      "Epoch 202 of 500 took 15.255s\n",
      "  training loss:\t\t0.877204\n",
      "  validation loss:\t\t0.911602\n",
      "  validation accuracy:\t\t62.69 %\n",
      "Epoch 203 of 500 took 16.697s\n",
      "  training loss:\t\t0.876066\n",
      "  validation loss:\t\t0.905107\n",
      "  validation accuracy:\t\t63.16 %\n",
      "Epoch 204 of 500 took 15.709s\n",
      "  training loss:\t\t0.879512\n",
      "  validation loss:\t\t0.907313\n",
      "  validation accuracy:\t\t63.00 %\n",
      "Epoch 205 of 500 took 19.494s\n",
      "  training loss:\t\t0.878104\n",
      "  validation loss:\t\t0.905554\n",
      "  validation accuracy:\t\t63.10 %\n",
      "Epoch 206 of 500 took 15.408s\n",
      "  training loss:\t\t0.878036\n",
      "  validation loss:\t\t0.908129\n",
      "  validation accuracy:\t\t62.91 %\n",
      "Epoch 207 of 500 took 16.237s\n",
      "  training loss:\t\t0.876982\n",
      "  validation loss:\t\t0.913219\n",
      "  validation accuracy:\t\t62.87 %\n",
      "Epoch 208 of 500 took 16.157s\n",
      "  training loss:\t\t0.877364\n",
      "  validation loss:\t\t0.920583\n",
      "  validation accuracy:\t\t62.50 %\n",
      "Epoch 209 of 500 took 15.808s\n",
      "  training loss:\t\t0.877343\n",
      "  validation loss:\t\t0.911491\n",
      "  validation accuracy:\t\t62.41 %\n",
      "Epoch 210 of 500 took 15.667s\n",
      "  training loss:\t\t0.875662\n",
      "  validation loss:\t\t0.914432\n",
      "  validation accuracy:\t\t62.57 %\n",
      "Epoch 211 of 500 took 16.134s\n",
      "  training loss:\t\t0.876317\n",
      "  validation loss:\t\t0.898228\n",
      "  validation accuracy:\t\t63.64 %\n",
      "Epoch 212 of 500 took 15.550s\n",
      "  training loss:\t\t0.872759\n",
      "  validation loss:\t\t0.902220\n",
      "  validation accuracy:\t\t63.33 %\n",
      "Epoch 213 of 500 took 15.514s\n",
      "  training loss:\t\t0.873634\n",
      "  validation loss:\t\t0.920982\n",
      "  validation accuracy:\t\t61.85 %\n",
      "Epoch 214 of 500 took 16.264s\n",
      "  training loss:\t\t0.872455\n",
      "  validation loss:\t\t0.916439\n",
      "  validation accuracy:\t\t62.63 %\n",
      "Epoch 215 of 500 took 15.700s\n",
      "  training loss:\t\t0.873183\n",
      "  validation loss:\t\t0.906677\n",
      "  validation accuracy:\t\t62.82 %\n",
      "Epoch 216 of 500 took 15.343s\n",
      "  training loss:\t\t0.873727\n",
      "  validation loss:\t\t0.909080\n",
      "  validation accuracy:\t\t62.88 %\n",
      "Epoch 217 of 500 took 15.847s\n",
      "  training loss:\t\t0.871918\n",
      "  validation loss:\t\t0.909238\n",
      "  validation accuracy:\t\t62.65 %\n",
      "Epoch 218 of 500 took 15.516s\n",
      "  training loss:\t\t0.873090\n",
      "  validation loss:\t\t0.905142\n",
      "  validation accuracy:\t\t62.97 %\n",
      "Epoch 219 of 500 took 16.443s\n",
      "  training loss:\t\t0.871982\n",
      "  validation loss:\t\t0.910017\n",
      "  validation accuracy:\t\t62.90 %\n",
      "Epoch 220 of 500 took 15.518s\n",
      "  training loss:\t\t0.871991\n",
      "  validation loss:\t\t0.916377\n",
      "  validation accuracy:\t\t62.44 %\n",
      "Epoch 221 of 500 took 15.886s\n",
      "  training loss:\t\t0.868724\n",
      "  validation loss:\t\t0.913653\n",
      "  validation accuracy:\t\t62.83 %\n",
      "Epoch 222 of 500 took 18.192s\n",
      "  training loss:\t\t0.871837\n",
      "  validation loss:\t\t0.911297\n",
      "  validation accuracy:\t\t62.68 %\n",
      "Epoch 223 of 500 took 14.901s\n",
      "  training loss:\t\t0.870853\n",
      "  validation loss:\t\t0.909006\n",
      "  validation accuracy:\t\t62.81 %\n",
      "Epoch 224 of 500 took 14.926s\n",
      "  training loss:\t\t0.868220\n",
      "  validation loss:\t\t0.894323\n",
      "  validation accuracy:\t\t63.50 %\n",
      "Epoch 225 of 500 took 14.904s\n",
      "  training loss:\t\t0.870222\n",
      "  validation loss:\t\t0.903229\n",
      "  validation accuracy:\t\t63.14 %\n",
      "Epoch 226 of 500 took 14.837s\n",
      "  training loss:\t\t0.869654\n",
      "  validation loss:\t\t0.903264\n",
      "  validation accuracy:\t\t63.21 %\n",
      "Epoch 227 of 500 took 15.786s\n",
      "  training loss:\t\t0.868053\n",
      "  validation loss:\t\t0.906260\n",
      "  validation accuracy:\t\t62.98 %\n",
      "Epoch 228 of 500 took 16.655s\n",
      "  training loss:\t\t0.868370\n",
      "  validation loss:\t\t0.902252\n",
      "  validation accuracy:\t\t63.29 %\n",
      "Epoch 229 of 500 took 15.933s\n",
      "  training loss:\t\t0.870212\n",
      "  validation loss:\t\t0.899770\n",
      "  validation accuracy:\t\t63.31 %\n",
      "Epoch 230 of 500 took 13.139s\n",
      "  training loss:\t\t0.867244\n",
      "  validation loss:\t\t0.901481\n",
      "  validation accuracy:\t\t63.27 %\n",
      "Epoch 231 of 500 took 14.581s\n",
      "  training loss:\t\t0.865632\n",
      "  validation loss:\t\t0.909956\n",
      "  validation accuracy:\t\t62.72 %\n",
      "Epoch 232 of 500 took 13.380s\n",
      "  training loss:\t\t0.866007\n",
      "  validation loss:\t\t0.905732\n",
      "  validation accuracy:\t\t62.89 %\n",
      "Epoch 233 of 500 took 13.928s\n",
      "  training loss:\t\t0.867287\n",
      "  validation loss:\t\t0.914383\n",
      "  validation accuracy:\t\t62.56 %\n",
      "Epoch 234 of 500 took 14.542s\n",
      "  training loss:\t\t0.868061\n",
      "  validation loss:\t\t0.913604\n",
      "  validation accuracy:\t\t62.72 %\n",
      "Epoch 235 of 500 took 13.295s\n",
      "  training loss:\t\t0.863978\n",
      "  validation loss:\t\t0.903877\n",
      "  validation accuracy:\t\t63.20 %\n",
      "Epoch 236 of 500 took 13.549s\n",
      "  training loss:\t\t0.865106\n",
      "  validation loss:\t\t0.903281\n",
      "  validation accuracy:\t\t63.34 %\n",
      "Epoch 237 of 500 took 13.128s\n",
      "  training loss:\t\t0.865975\n",
      "  validation loss:\t\t0.908284\n",
      "  validation accuracy:\t\t62.79 %\n",
      "Epoch 238 of 500 took 13.076s\n",
      "  training loss:\t\t0.863163\n",
      "  validation loss:\t\t0.903773\n",
      "  validation accuracy:\t\t63.26 %\n",
      "Epoch 239 of 500 took 13.151s\n",
      "  training loss:\t\t0.862394\n",
      "  validation loss:\t\t0.906755\n",
      "  validation accuracy:\t\t62.83 %\n",
      "Epoch 240 of 500 took 13.265s\n",
      "  training loss:\t\t0.863199\n",
      "  validation loss:\t\t0.909632\n",
      "  validation accuracy:\t\t62.55 %\n",
      "Epoch 241 of 500 took 13.349s\n",
      "  training loss:\t\t0.863745\n",
      "  validation loss:\t\t0.905769\n",
      "  validation accuracy:\t\t62.62 %\n",
      "Epoch 242 of 500 took 14.272s\n",
      "  training loss:\t\t0.860971\n",
      "  validation loss:\t\t0.893970\n",
      "  validation accuracy:\t\t63.56 %\n",
      "Epoch 243 of 500 took 13.294s\n",
      "  training loss:\t\t0.862301\n",
      "  validation loss:\t\t0.899250\n",
      "  validation accuracy:\t\t63.41 %\n",
      "Epoch 244 of 500 took 13.703s\n",
      "  training loss:\t\t0.861528\n",
      "  validation loss:\t\t0.911844\n",
      "  validation accuracy:\t\t62.64 %\n",
      "Epoch 245 of 500 took 13.277s\n",
      "  training loss:\t\t0.863084\n",
      "  validation loss:\t\t0.898914\n",
      "  validation accuracy:\t\t63.33 %\n",
      "Epoch 246 of 500 took 13.497s\n",
      "  training loss:\t\t0.860043\n",
      "  validation loss:\t\t0.899560\n",
      "  validation accuracy:\t\t63.35 %\n",
      "Epoch 247 of 500 took 20.320s\n",
      "  training loss:\t\t0.859785\n",
      "  validation loss:\t\t0.907576\n",
      "  validation accuracy:\t\t62.68 %\n",
      "Epoch 248 of 500 took 17.624s\n",
      "  training loss:\t\t0.861683\n",
      "  validation loss:\t\t0.910070\n",
      "  validation accuracy:\t\t62.84 %\n",
      "Epoch 249 of 500 took 14.006s\n",
      "  training loss:\t\t0.863414\n",
      "  validation loss:\t\t0.902191\n",
      "  validation accuracy:\t\t63.07 %\n",
      "Epoch 250 of 500 took 15.936s\n",
      "  training loss:\t\t0.859514\n",
      "  validation loss:\t\t0.909242\n",
      "  validation accuracy:\t\t62.38 %\n",
      "Epoch 251 of 500 took 15.217s\n",
      "  training loss:\t\t0.858241\n",
      "  validation loss:\t\t0.916920\n",
      "  validation accuracy:\t\t62.16 %\n",
      "Epoch 252 of 500 took 15.856s\n",
      "  training loss:\t\t0.862390\n",
      "  validation loss:\t\t0.901874\n",
      "  validation accuracy:\t\t62.88 %\n",
      "Epoch 253 of 500 took 14.125s\n",
      "  training loss:\t\t0.862237\n",
      "  validation loss:\t\t0.919008\n",
      "  validation accuracy:\t\t61.73 %\n",
      "Epoch 254 of 500 took 17.519s\n",
      "  training loss:\t\t0.857317\n",
      "  validation loss:\t\t0.894033\n",
      "  validation accuracy:\t\t63.41 %\n",
      "Epoch 255 of 500 took 18.232s\n",
      "  training loss:\t\t0.859385\n",
      "  validation loss:\t\t0.898305\n",
      "  validation accuracy:\t\t62.84 %\n",
      "Epoch 256 of 500 took 17.797s\n",
      "  training loss:\t\t0.858264\n",
      "  validation loss:\t\t0.897858\n",
      "  validation accuracy:\t\t63.42 %\n",
      "Epoch 257 of 500 took 14.948s\n",
      "  training loss:\t\t0.857646\n",
      "  validation loss:\t\t0.902131\n",
      "  validation accuracy:\t\t62.94 %\n",
      "Epoch 258 of 500 took 14.876s\n",
      "  training loss:\t\t0.856876\n",
      "  validation loss:\t\t0.897621\n",
      "  validation accuracy:\t\t63.35 %\n",
      "Epoch 259 of 500 took 13.993s\n",
      "  training loss:\t\t0.854711\n",
      "  validation loss:\t\t0.907169\n",
      "  validation accuracy:\t\t62.58 %\n",
      "Epoch 260 of 500 took 13.880s\n",
      "  training loss:\t\t0.855003\n",
      "  validation loss:\t\t0.892072\n",
      "  validation accuracy:\t\t63.59 %\n",
      "Epoch 261 of 500 took 15.005s\n",
      "  training loss:\t\t0.856394\n",
      "  validation loss:\t\t0.908957\n",
      "  validation accuracy:\t\t62.70 %\n",
      "Epoch 262 of 500 took 14.165s\n",
      "  training loss:\t\t0.853674\n",
      "  validation loss:\t\t0.905481\n",
      "  validation accuracy:\t\t62.81 %\n",
      "Epoch 263 of 500 took 16.613s\n",
      "  training loss:\t\t0.855224\n",
      "  validation loss:\t\t0.909151\n",
      "  validation accuracy:\t\t62.48 %\n",
      "Epoch 264 of 500 took 15.527s\n",
      "  training loss:\t\t0.856116\n",
      "  validation loss:\t\t0.903112\n",
      "  validation accuracy:\t\t62.91 %\n",
      "Epoch 265 of 500 took 15.425s\n",
      "  training loss:\t\t0.853481\n",
      "  validation loss:\t\t0.896865\n",
      "  validation accuracy:\t\t63.23 %\n",
      "Epoch 266 of 500 took 14.206s\n",
      "  training loss:\t\t0.851112\n",
      "  validation loss:\t\t0.897776\n",
      "  validation accuracy:\t\t63.13 %\n",
      "Epoch 267 of 500 took 14.769s\n",
      "  training loss:\t\t0.854947\n",
      "  validation loss:\t\t0.897486\n",
      "  validation accuracy:\t\t63.53 %\n",
      "Epoch 268 of 500 took 14.089s\n",
      "  training loss:\t\t0.852365\n",
      "  validation loss:\t\t0.898327\n",
      "  validation accuracy:\t\t63.35 %\n",
      "Epoch 269 of 500 took 14.087s\n",
      "  training loss:\t\t0.851180\n",
      "  validation loss:\t\t0.903353\n",
      "  validation accuracy:\t\t62.71 %\n",
      "Epoch 270 of 500 took 15.154s\n",
      "  training loss:\t\t0.851486\n",
      "  validation loss:\t\t0.901392\n",
      "  validation accuracy:\t\t63.18 %\n",
      "Epoch 271 of 500 took 18.658s\n",
      "  training loss:\t\t0.852460\n",
      "  validation loss:\t\t0.898810\n",
      "  validation accuracy:\t\t63.16 %\n",
      "Epoch 272 of 500 took 16.765s\n",
      "  training loss:\t\t0.850138\n",
      "  validation loss:\t\t0.910867\n",
      "  validation accuracy:\t\t62.53 %\n",
      "Epoch 273 of 500 took 15.933s\n",
      "  training loss:\t\t0.851469\n",
      "  validation loss:\t\t0.899331\n",
      "  validation accuracy:\t\t63.22 %\n",
      "Epoch 274 of 500 took 14.306s\n",
      "  training loss:\t\t0.849238\n",
      "  validation loss:\t\t0.900101\n",
      "  validation accuracy:\t\t63.45 %\n",
      "Epoch 275 of 500 took 13.612s\n",
      "  training loss:\t\t0.850693\n",
      "  validation loss:\t\t0.892276\n",
      "  validation accuracy:\t\t63.46 %\n",
      "Epoch 276 of 500 took 14.219s\n",
      "  training loss:\t\t0.848495\n",
      "  validation loss:\t\t0.906253\n",
      "  validation accuracy:\t\t62.51 %\n",
      "Epoch 277 of 500 took 16.573s\n",
      "  training loss:\t\t0.850039\n",
      "  validation loss:\t\t0.900645\n",
      "  validation accuracy:\t\t63.09 %\n",
      "Epoch 278 of 500 took 18.074s\n",
      "  training loss:\t\t0.847037\n",
      "  validation loss:\t\t0.895814\n",
      "  validation accuracy:\t\t63.23 %\n",
      "Epoch 279 of 500 took 16.829s\n",
      "  training loss:\t\t0.848042\n",
      "  validation loss:\t\t0.899635\n",
      "  validation accuracy:\t\t63.42 %\n",
      "Epoch 280 of 500 took 19.225s\n",
      "  training loss:\t\t0.849398\n",
      "  validation loss:\t\t0.910355\n",
      "  validation accuracy:\t\t62.93 %\n",
      "Epoch 281 of 500 took 17.470s\n",
      "  training loss:\t\t0.846486\n",
      "  validation loss:\t\t0.900079\n",
      "  validation accuracy:\t\t63.21 %\n",
      "Epoch 282 of 500 took 16.208s\n",
      "  training loss:\t\t0.849764\n",
      "  validation loss:\t\t0.916505\n",
      "  validation accuracy:\t\t62.19 %\n",
      "Epoch 283 of 500 took 15.168s\n",
      "  training loss:\t\t0.846865\n",
      "  validation loss:\t\t0.899378\n",
      "  validation accuracy:\t\t63.18 %\n",
      "Epoch 284 of 500 took 15.452s\n",
      "  training loss:\t\t0.846249\n",
      "  validation loss:\t\t0.906358\n",
      "  validation accuracy:\t\t62.68 %\n",
      "Epoch 285 of 500 took 15.343s\n",
      "  training loss:\t\t0.845479\n",
      "  validation loss:\t\t0.898475\n",
      "  validation accuracy:\t\t63.14 %\n",
      "Epoch 286 of 500 took 14.991s\n",
      "  training loss:\t\t0.844941\n",
      "  validation loss:\t\t0.894999\n",
      "  validation accuracy:\t\t63.63 %\n",
      "Epoch 287 of 500 took 16.479s\n",
      "  training loss:\t\t0.845007\n",
      "  validation loss:\t\t0.891625\n",
      "  validation accuracy:\t\t63.77 %\n",
      "Epoch 288 of 500 took 15.040s\n",
      "  training loss:\t\t0.846887\n",
      "  validation loss:\t\t0.904447\n",
      "  validation accuracy:\t\t62.91 %\n",
      "Epoch 289 of 500 took 14.902s\n",
      "  training loss:\t\t0.844364\n",
      "  validation loss:\t\t0.902344\n",
      "  validation accuracy:\t\t63.10 %\n",
      "Epoch 290 of 500 took 16.049s\n",
      "  training loss:\t\t0.845033\n",
      "  validation loss:\t\t0.903955\n",
      "  validation accuracy:\t\t62.90 %\n",
      "Epoch 291 of 500 took 15.311s\n",
      "  training loss:\t\t0.844928\n",
      "  validation loss:\t\t0.898320\n",
      "  validation accuracy:\t\t63.08 %\n",
      "Epoch 292 of 500 took 14.171s\n",
      "  training loss:\t\t0.844456\n",
      "  validation loss:\t\t0.898909\n",
      "  validation accuracy:\t\t62.95 %\n",
      "Epoch 293 of 500 took 15.063s\n",
      "  training loss:\t\t0.842353\n",
      "  validation loss:\t\t0.898512\n",
      "  validation accuracy:\t\t63.15 %\n",
      "Epoch 294 of 500 took 15.961s\n",
      "  training loss:\t\t0.842995\n",
      "  validation loss:\t\t0.895672\n",
      "  validation accuracy:\t\t63.17 %\n",
      "Epoch 295 of 500 took 14.940s\n",
      "  training loss:\t\t0.844099\n",
      "  validation loss:\t\t0.893925\n",
      "  validation accuracy:\t\t63.22 %\n",
      "Epoch 296 of 500 took 14.738s\n",
      "  training loss:\t\t0.842300\n",
      "  validation loss:\t\t0.894243\n",
      "  validation accuracy:\t\t63.51 %\n",
      "Epoch 297 of 500 took 14.805s\n",
      "  training loss:\t\t0.842217\n",
      "  validation loss:\t\t0.894975\n",
      "  validation accuracy:\t\t63.26 %\n",
      "Epoch 298 of 500 took 15.860s\n",
      "  training loss:\t\t0.842460\n",
      "  validation loss:\t\t0.897343\n",
      "  validation accuracy:\t\t63.31 %\n",
      "Epoch 299 of 500 took 15.880s\n",
      "  training loss:\t\t0.840489\n",
      "  validation loss:\t\t0.895717\n",
      "  validation accuracy:\t\t63.71 %\n",
      "Epoch 300 of 500 took 16.368s\n",
      "  training loss:\t\t0.841332\n",
      "  validation loss:\t\t0.897769\n",
      "  validation accuracy:\t\t63.10 %\n",
      "Epoch 301 of 500 took 15.382s\n",
      "  training loss:\t\t0.843190\n",
      "  validation loss:\t\t0.896507\n",
      "  validation accuracy:\t\t63.21 %\n",
      "Epoch 302 of 500 took 17.205s\n",
      "  training loss:\t\t0.840378\n",
      "  validation loss:\t\t0.902881\n",
      "  validation accuracy:\t\t62.60 %\n",
      "Epoch 303 of 500 took 15.755s\n",
      "  training loss:\t\t0.840188\n",
      "  validation loss:\t\t0.885463\n",
      "  validation accuracy:\t\t63.92 %\n",
      "Epoch 304 of 500 took 20.314s\n",
      "  training loss:\t\t0.841356\n",
      "  validation loss:\t\t0.902624\n",
      "  validation accuracy:\t\t63.07 %\n",
      "Epoch 305 of 500 took 15.986s\n",
      "  training loss:\t\t0.840126\n",
      "  validation loss:\t\t0.891611\n",
      "  validation accuracy:\t\t63.67 %\n",
      "Epoch 306 of 500 took 16.159s\n",
      "  training loss:\t\t0.838281\n",
      "  validation loss:\t\t0.891805\n",
      "  validation accuracy:\t\t63.47 %\n",
      "Epoch 307 of 500 took 15.381s\n",
      "  training loss:\t\t0.839798\n",
      "  validation loss:\t\t0.906496\n",
      "  validation accuracy:\t\t62.46 %\n",
      "Epoch 308 of 500 took 15.509s\n",
      "  training loss:\t\t0.839361\n",
      "  validation loss:\t\t0.893873\n",
      "  validation accuracy:\t\t63.28 %\n",
      "Epoch 309 of 500 took 14.720s\n",
      "  training loss:\t\t0.837833\n",
      "  validation loss:\t\t0.885714\n",
      "  validation accuracy:\t\t64.12 %\n",
      "Epoch 310 of 500 took 15.378s\n",
      "  training loss:\t\t0.835679\n",
      "  validation loss:\t\t0.890267\n",
      "  validation accuracy:\t\t63.61 %\n",
      "Epoch 311 of 500 took 17.579s\n",
      "  training loss:\t\t0.837454\n",
      "  validation loss:\t\t0.894514\n",
      "  validation accuracy:\t\t63.43 %\n",
      "Epoch 312 of 500 took 15.456s\n",
      "  training loss:\t\t0.834051\n",
      "  validation loss:\t\t0.895879\n",
      "  validation accuracy:\t\t63.13 %\n",
      "Epoch 313 of 500 took 14.724s\n",
      "  training loss:\t\t0.836758\n",
      "  validation loss:\t\t0.899782\n",
      "  validation accuracy:\t\t62.95 %\n",
      "Epoch 314 of 500 took 19.868s\n",
      "  training loss:\t\t0.834671\n",
      "  validation loss:\t\t0.900997\n",
      "  validation accuracy:\t\t63.15 %\n",
      "Epoch 315 of 500 took 15.702s\n",
      "  training loss:\t\t0.835513\n",
      "  validation loss:\t\t0.897229\n",
      "  validation accuracy:\t\t63.16 %\n",
      "Epoch 316 of 500 took 14.289s\n",
      "  training loss:\t\t0.836983\n",
      "  validation loss:\t\t0.897229\n",
      "  validation accuracy:\t\t63.34 %\n",
      "Epoch 317 of 500 took 17.446s\n",
      "  training loss:\t\t0.836018\n",
      "  validation loss:\t\t0.901359\n",
      "  validation accuracy:\t\t62.81 %\n",
      "Epoch 318 of 500 took 14.161s\n",
      "  training loss:\t\t0.836409\n",
      "  validation loss:\t\t0.896654\n",
      "  validation accuracy:\t\t62.95 %\n",
      "Epoch 319 of 500 took 14.179s\n",
      "  training loss:\t\t0.834226\n",
      "  validation loss:\t\t0.898771\n",
      "  validation accuracy:\t\t63.26 %\n",
      "Epoch 320 of 500 took 14.851s\n",
      "  training loss:\t\t0.833721\n",
      "  validation loss:\t\t0.904397\n",
      "  validation accuracy:\t\t62.82 %\n",
      "Epoch 321 of 500 took 15.161s\n",
      "  training loss:\t\t0.832838\n",
      "  validation loss:\t\t0.911436\n",
      "  validation accuracy:\t\t62.27 %\n",
      "Epoch 322 of 500 took 14.378s\n",
      "  training loss:\t\t0.831561\n",
      "  validation loss:\t\t0.896381\n",
      "  validation accuracy:\t\t63.44 %\n",
      "Epoch 323 of 500 took 13.279s\n",
      "  training loss:\t\t0.832050\n",
      "  validation loss:\t\t0.885688\n",
      "  validation accuracy:\t\t64.07 %\n",
      "Epoch 324 of 500 took 13.393s\n",
      "  training loss:\t\t0.833457\n",
      "  validation loss:\t\t0.908679\n",
      "  validation accuracy:\t\t62.80 %\n",
      "Epoch 325 of 500 took 13.877s\n",
      "  training loss:\t\t0.832410\n",
      "  validation loss:\t\t0.904900\n",
      "  validation accuracy:\t\t62.80 %\n",
      "Epoch 326 of 500 took 13.757s\n",
      "  training loss:\t\t0.832440\n",
      "  validation loss:\t\t0.904388\n",
      "  validation accuracy:\t\t62.46 %\n",
      "Epoch 327 of 500 took 13.955s\n",
      "  training loss:\t\t0.831669\n",
      "  validation loss:\t\t0.897953\n",
      "  validation accuracy:\t\t63.14 %\n",
      "Epoch 328 of 500 took 13.962s\n",
      "  training loss:\t\t0.829083\n",
      "  validation loss:\t\t0.895109\n",
      "  validation accuracy:\t\t63.39 %\n",
      "Epoch 329 of 500 took 13.890s\n",
      "  training loss:\t\t0.831363\n",
      "  validation loss:\t\t0.886527\n",
      "  validation accuracy:\t\t63.79 %\n",
      "Epoch 330 of 500 took 19.969s\n",
      "  training loss:\t\t0.829956\n",
      "  validation loss:\t\t0.898001\n",
      "  validation accuracy:\t\t63.09 %\n",
      "Epoch 331 of 500 took 20.923s\n",
      "  training loss:\t\t0.828714\n",
      "  validation loss:\t\t0.890949\n",
      "  validation accuracy:\t\t63.62 %\n",
      "Epoch 332 of 500 took 19.727s\n",
      "  training loss:\t\t0.829176\n",
      "  validation loss:\t\t0.892265\n",
      "  validation accuracy:\t\t63.54 %\n",
      "Epoch 333 of 500 took 16.766s\n",
      "  training loss:\t\t0.828143\n",
      "  validation loss:\t\t0.906952\n",
      "  validation accuracy:\t\t62.71 %\n",
      "Epoch 334 of 500 took 17.048s\n",
      "  training loss:\t\t0.829892\n",
      "  validation loss:\t\t0.898639\n",
      "  validation accuracy:\t\t63.16 %\n",
      "Epoch 335 of 500 took 16.696s\n",
      "  training loss:\t\t0.829399\n",
      "  validation loss:\t\t0.893382\n",
      "  validation accuracy:\t\t63.20 %\n",
      "Epoch 336 of 500 took 15.324s\n",
      "  training loss:\t\t0.827493\n",
      "  validation loss:\t\t0.894908\n",
      "  validation accuracy:\t\t63.21 %\n",
      "Epoch 337 of 500 took 15.115s\n",
      "  training loss:\t\t0.830241\n",
      "  validation loss:\t\t0.902846\n",
      "  validation accuracy:\t\t62.83 %\n",
      "Epoch 338 of 500 took 15.375s\n",
      "  training loss:\t\t0.828021\n",
      "  validation loss:\t\t0.895151\n",
      "  validation accuracy:\t\t63.28 %\n",
      "Epoch 339 of 500 took 14.265s\n",
      "  training loss:\t\t0.826928\n",
      "  validation loss:\t\t0.911076\n",
      "  validation accuracy:\t\t62.13 %\n",
      "Epoch 340 of 500 took 13.364s\n",
      "  training loss:\t\t0.826173\n",
      "  validation loss:\t\t0.902023\n",
      "  validation accuracy:\t\t62.92 %\n",
      "Epoch 341 of 500 took 17.659s\n",
      "  training loss:\t\t0.821788\n",
      "  validation loss:\t\t0.896684\n",
      "  validation accuracy:\t\t63.13 %\n",
      "Epoch 342 of 500 took 17.363s\n",
      "  training loss:\t\t0.825928\n",
      "  validation loss:\t\t0.896727\n",
      "  validation accuracy:\t\t63.30 %\n",
      "Epoch 343 of 500 took 16.999s\n",
      "  training loss:\t\t0.826440\n",
      "  validation loss:\t\t0.904238\n",
      "  validation accuracy:\t\t63.25 %\n",
      "Epoch 344 of 500 took 16.224s\n",
      "  training loss:\t\t0.824760\n",
      "  validation loss:\t\t0.891407\n",
      "  validation accuracy:\t\t63.12 %\n",
      "Epoch 345 of 500 took 14.830s\n",
      "  training loss:\t\t0.823505\n",
      "  validation loss:\t\t0.904945\n",
      "  validation accuracy:\t\t62.16 %\n",
      "Epoch 346 of 500 took 15.787s\n",
      "  training loss:\t\t0.825386\n",
      "  validation loss:\t\t0.906483\n",
      "  validation accuracy:\t\t62.30 %\n",
      "Epoch 347 of 500 took 16.794s\n",
      "  training loss:\t\t0.824520\n",
      "  validation loss:\t\t0.890978\n",
      "  validation accuracy:\t\t63.34 %\n",
      "Epoch 348 of 500 took 17.131s\n",
      "  training loss:\t\t0.829383\n",
      "  validation loss:\t\t0.892656\n",
      "  validation accuracy:\t\t63.47 %\n",
      "Epoch 349 of 500 took 16.395s\n",
      "  training loss:\t\t0.824645\n",
      "  validation loss:\t\t0.909316\n",
      "  validation accuracy:\t\t62.25 %\n",
      "Epoch 350 of 500 took 21.388s\n",
      "  training loss:\t\t0.821931\n",
      "  validation loss:\t\t0.898277\n",
      "  validation accuracy:\t\t62.98 %\n",
      "Epoch 351 of 500 took 20.146s\n",
      "  training loss:\t\t0.823849\n",
      "  validation loss:\t\t0.893299\n",
      "  validation accuracy:\t\t63.29 %\n",
      "Epoch 352 of 500 took 15.957s\n",
      "  training loss:\t\t0.822402\n",
      "  validation loss:\t\t0.903754\n",
      "  validation accuracy:\t\t62.87 %\n",
      "Epoch 353 of 500 took 16.462s\n",
      "  training loss:\t\t0.822763\n",
      "  validation loss:\t\t0.894914\n",
      "  validation accuracy:\t\t63.32 %\n",
      "Epoch 354 of 500 took 16.131s\n",
      "  training loss:\t\t0.821953\n",
      "  validation loss:\t\t0.889504\n",
      "  validation accuracy:\t\t63.72 %\n",
      "Epoch 355 of 500 took 17.279s\n",
      "  training loss:\t\t0.824567\n",
      "  validation loss:\t\t0.904675\n",
      "  validation accuracy:\t\t62.94 %\n",
      "Epoch 356 of 500 took 13.925s\n",
      "  training loss:\t\t0.820168\n",
      "  validation loss:\t\t0.896871\n",
      "  validation accuracy:\t\t62.97 %\n",
      "Epoch 357 of 500 took 13.921s\n",
      "  training loss:\t\t0.820079\n",
      "  validation loss:\t\t0.891868\n",
      "  validation accuracy:\t\t63.22 %\n",
      "Epoch 358 of 500 took 14.509s\n",
      "  training loss:\t\t0.822062\n",
      "  validation loss:\t\t0.903095\n",
      "  validation accuracy:\t\t62.41 %\n",
      "Epoch 359 of 500 took 15.807s\n",
      "  training loss:\t\t0.821679\n",
      "  validation loss:\t\t0.913018\n",
      "  validation accuracy:\t\t62.35 %\n",
      "Epoch 360 of 500 took 14.934s\n",
      "  training loss:\t\t0.821217\n",
      "  validation loss:\t\t0.898535\n",
      "  validation accuracy:\t\t63.02 %\n",
      "Epoch 361 of 500 took 13.299s\n",
      "  training loss:\t\t0.819018\n",
      "  validation loss:\t\t0.896923\n",
      "  validation accuracy:\t\t63.03 %\n",
      "Epoch 362 of 500 took 13.145s\n",
      "  training loss:\t\t0.820110\n",
      "  validation loss:\t\t0.901504\n",
      "  validation accuracy:\t\t62.84 %\n",
      "Epoch 363 of 500 took 13.125s\n",
      "  training loss:\t\t0.819282\n",
      "  validation loss:\t\t0.892047\n",
      "  validation accuracy:\t\t63.51 %\n",
      "Epoch 364 of 500 took 18.227s\n",
      "  training loss:\t\t0.820339\n",
      "  validation loss:\t\t0.903615\n",
      "  validation accuracy:\t\t63.17 %\n",
      "Epoch 365 of 500 took 15.467s\n",
      "  training loss:\t\t0.818785\n",
      "  validation loss:\t\t0.905873\n",
      "  validation accuracy:\t\t62.60 %\n",
      "Epoch 366 of 500 took 16.937s\n",
      "  training loss:\t\t0.816347\n",
      "  validation loss:\t\t0.892647\n",
      "  validation accuracy:\t\t63.70 %\n",
      "Epoch 367 of 500 took 16.133s\n",
      "  training loss:\t\t0.817629\n",
      "  validation loss:\t\t0.901557\n",
      "  validation accuracy:\t\t62.59 %\n",
      "Epoch 368 of 500 took 15.071s\n",
      "  training loss:\t\t0.816161\n",
      "  validation loss:\t\t0.884461\n",
      "  validation accuracy:\t\t64.04 %\n",
      "Epoch 369 of 500 took 14.984s\n",
      "  training loss:\t\t0.819517\n",
      "  validation loss:\t\t0.902322\n",
      "  validation accuracy:\t\t62.85 %\n",
      "Epoch 370 of 500 took 19.750s\n",
      "  training loss:\t\t0.818088\n",
      "  validation loss:\t\t0.899317\n",
      "  validation accuracy:\t\t62.63 %\n",
      "Epoch 371 of 500 took 22.914s\n",
      "  training loss:\t\t0.816965\n",
      "  validation loss:\t\t0.902571\n",
      "  validation accuracy:\t\t62.43 %\n",
      "Epoch 372 of 500 took 21.748s\n",
      "  training loss:\t\t0.819312\n",
      "  validation loss:\t\t0.919203\n",
      "  validation accuracy:\t\t61.96 %\n",
      "Epoch 373 of 500 took 15.516s\n",
      "  training loss:\t\t0.817113\n",
      "  validation loss:\t\t0.899475\n",
      "  validation accuracy:\t\t63.22 %\n",
      "Epoch 374 of 500 took 17.888s\n",
      "  training loss:\t\t0.815115\n",
      "  validation loss:\t\t0.890926\n",
      "  validation accuracy:\t\t63.74 %\n",
      "Epoch 375 of 500 took 19.202s\n",
      "  training loss:\t\t0.814416\n",
      "  validation loss:\t\t0.904930\n",
      "  validation accuracy:\t\t63.08 %\n",
      "Epoch 376 of 500 took 18.624s\n",
      "  training loss:\t\t0.814497\n",
      "  validation loss:\t\t0.893170\n",
      "  validation accuracy:\t\t63.09 %\n",
      "Epoch 377 of 500 took 14.488s\n",
      "  training loss:\t\t0.813309\n",
      "  validation loss:\t\t0.894180\n",
      "  validation accuracy:\t\t63.21 %\n",
      "Epoch 378 of 500 took 13.557s\n",
      "  training loss:\t\t0.813731\n",
      "  validation loss:\t\t0.906764\n",
      "  validation accuracy:\t\t62.84 %\n",
      "Epoch 379 of 500 took 15.804s\n",
      "  training loss:\t\t0.814782\n",
      "  validation loss:\t\t0.899165\n",
      "  validation accuracy:\t\t62.90 %\n",
      "Epoch 380 of 500 took 13.916s\n",
      "  training loss:\t\t0.815387\n",
      "  validation loss:\t\t0.901626\n",
      "  validation accuracy:\t\t63.12 %\n",
      "Epoch 381 of 500 took 14.436s\n",
      "  training loss:\t\t0.816921\n",
      "  validation loss:\t\t0.889993\n",
      "  validation accuracy:\t\t63.58 %\n",
      "Epoch 382 of 500 took 16.791s\n",
      "  training loss:\t\t0.814604\n",
      "  validation loss:\t\t0.901789\n",
      "  validation accuracy:\t\t63.08 %\n",
      "Epoch 383 of 500 took 19.539s\n",
      "  training loss:\t\t0.814276\n",
      "  validation loss:\t\t0.891116\n",
      "  validation accuracy:\t\t63.35 %\n",
      "Epoch 384 of 500 took 14.904s\n",
      "  training loss:\t\t0.811325\n",
      "  validation loss:\t\t0.905010\n",
      "  validation accuracy:\t\t62.85 %\n",
      "Epoch 385 of 500 took 15.804s\n",
      "  training loss:\t\t0.812745\n",
      "  validation loss:\t\t0.900350\n",
      "  validation accuracy:\t\t63.09 %\n",
      "Epoch 386 of 500 took 17.077s\n",
      "  training loss:\t\t0.811060\n",
      "  validation loss:\t\t0.895993\n",
      "  validation accuracy:\t\t63.20 %\n",
      "Epoch 387 of 500 took 21.987s\n",
      "  training loss:\t\t0.811636\n",
      "  validation loss:\t\t0.896845\n",
      "  validation accuracy:\t\t63.05 %\n",
      "Epoch 388 of 500 took 19.678s\n",
      "  training loss:\t\t0.813408\n",
      "  validation loss:\t\t0.883436\n",
      "  validation accuracy:\t\t63.97 %\n",
      "Epoch 389 of 500 took 18.858s\n",
      "  training loss:\t\t0.809310\n",
      "  validation loss:\t\t0.892011\n",
      "  validation accuracy:\t\t63.54 %\n",
      "Epoch 390 of 500 took 20.300s\n",
      "  training loss:\t\t0.813418\n",
      "  validation loss:\t\t0.897059\n",
      "  validation accuracy:\t\t63.17 %\n",
      "Epoch 391 of 500 took 19.708s\n",
      "  training loss:\t\t0.810489\n",
      "  validation loss:\t\t0.899815\n",
      "  validation accuracy:\t\t63.00 %\n",
      "Epoch 392 of 500 took 17.170s\n",
      "  training loss:\t\t0.811994\n",
      "  validation loss:\t\t0.891902\n",
      "  validation accuracy:\t\t63.36 %\n",
      "Epoch 393 of 500 took 18.428s\n",
      "  training loss:\t\t0.810200\n",
      "  validation loss:\t\t0.898741\n",
      "  validation accuracy:\t\t63.07 %\n",
      "Epoch 394 of 500 took 17.578s\n",
      "  training loss:\t\t0.812276\n",
      "  validation loss:\t\t0.896264\n",
      "  validation accuracy:\t\t63.44 %\n",
      "Epoch 395 of 500 took 17.221s\n",
      "  training loss:\t\t0.812727\n",
      "  validation loss:\t\t0.908815\n",
      "  validation accuracy:\t\t62.34 %\n",
      "Epoch 396 of 500 took 19.400s\n",
      "  training loss:\t\t0.809507\n",
      "  validation loss:\t\t0.893516\n",
      "  validation accuracy:\t\t63.61 %\n",
      "Epoch 397 of 500 took 18.837s\n",
      "  training loss:\t\t0.811631\n",
      "  validation loss:\t\t0.906786\n",
      "  validation accuracy:\t\t62.36 %\n",
      "Epoch 398 of 500 took 17.305s\n",
      "  training loss:\t\t0.805166\n",
      "  validation loss:\t\t0.896985\n",
      "  validation accuracy:\t\t63.44 %\n",
      "Epoch 399 of 500 took 20.392s\n",
      "  training loss:\t\t0.811694\n",
      "  validation loss:\t\t0.891084\n",
      "  validation accuracy:\t\t63.17 %\n",
      "Epoch 400 of 500 took 21.768s\n",
      "  training loss:\t\t0.805750\n",
      "  validation loss:\t\t0.901932\n",
      "  validation accuracy:\t\t63.18 %\n",
      "Epoch 401 of 500 took 21.777s\n",
      "  training loss:\t\t0.806439\n",
      "  validation loss:\t\t0.911331\n",
      "  validation accuracy:\t\t62.27 %\n",
      "Epoch 402 of 500 took 21.832s\n",
      "  training loss:\t\t0.809030\n",
      "  validation loss:\t\t0.899669\n",
      "  validation accuracy:\t\t63.17 %\n",
      "Epoch 403 of 500 took 21.753s\n",
      "  training loss:\t\t0.807909\n",
      "  validation loss:\t\t0.898322\n",
      "  validation accuracy:\t\t63.02 %\n",
      "Epoch 404 of 500 took 21.739s\n",
      "  training loss:\t\t0.808603\n",
      "  validation loss:\t\t0.896984\n",
      "  validation accuracy:\t\t62.78 %\n",
      "Epoch 405 of 500 took 21.865s\n",
      "  training loss:\t\t0.808538\n",
      "  validation loss:\t\t0.898966\n",
      "  validation accuracy:\t\t62.68 %\n",
      "Epoch 406 of 500 took 21.764s\n",
      "  training loss:\t\t0.805579\n",
      "  validation loss:\t\t0.895673\n",
      "  validation accuracy:\t\t63.38 %\n",
      "Epoch 407 of 500 took 21.735s\n",
      "  training loss:\t\t0.807495\n",
      "  validation loss:\t\t0.906285\n",
      "  validation accuracy:\t\t62.59 %\n",
      "Epoch 408 of 500 took 21.738s\n",
      "  training loss:\t\t0.804545\n",
      "  validation loss:\t\t0.900438\n",
      "  validation accuracy:\t\t63.37 %\n",
      "Epoch 409 of 500 took 19.122s\n",
      "  training loss:\t\t0.809003\n",
      "  validation loss:\t\t0.896628\n",
      "  validation accuracy:\t\t63.07 %\n",
      "Epoch 410 of 500 took 13.327s\n",
      "  training loss:\t\t0.803374\n",
      "  validation loss:\t\t0.894803\n",
      "  validation accuracy:\t\t63.36 %\n",
      "Epoch 411 of 500 took 13.228s\n",
      "  training loss:\t\t0.806696\n",
      "  validation loss:\t\t0.885237\n",
      "  validation accuracy:\t\t63.67 %\n",
      "Epoch 412 of 500 took 13.225s\n",
      "  training loss:\t\t0.803027\n",
      "  validation loss:\t\t0.899001\n",
      "  validation accuracy:\t\t62.80 %\n",
      "Epoch 413 of 500 took 13.298s\n",
      "  training loss:\t\t0.803626\n",
      "  validation loss:\t\t0.906476\n",
      "  validation accuracy:\t\t62.66 %\n",
      "Epoch 414 of 500 took 13.760s\n",
      "  training loss:\t\t0.803926\n",
      "  validation loss:\t\t0.908687\n",
      "  validation accuracy:\t\t62.36 %\n",
      "Epoch 415 of 500 took 14.505s\n",
      "  training loss:\t\t0.803099\n",
      "  validation loss:\t\t0.894774\n",
      "  validation accuracy:\t\t63.37 %\n",
      "Epoch 416 of 500 took 19.036s\n",
      "  training loss:\t\t0.802858\n",
      "  validation loss:\t\t0.887474\n",
      "  validation accuracy:\t\t63.67 %\n",
      "Epoch 417 of 500 took 21.682s\n",
      "  training loss:\t\t0.804987\n",
      "  validation loss:\t\t0.896639\n",
      "  validation accuracy:\t\t63.15 %\n",
      "Epoch 418 of 500 took 20.610s\n",
      "  training loss:\t\t0.801310\n",
      "  validation loss:\t\t0.893530\n",
      "  validation accuracy:\t\t63.41 %\n",
      "Epoch 419 of 500 took 18.418s\n",
      "  training loss:\t\t0.802560\n",
      "  validation loss:\t\t0.900786\n",
      "  validation accuracy:\t\t63.23 %\n",
      "Epoch 420 of 500 took 18.594s\n",
      "  training loss:\t\t0.801873\n",
      "  validation loss:\t\t0.895090\n",
      "  validation accuracy:\t\t63.47 %\n",
      "Epoch 421 of 500 took 20.898s\n",
      "  training loss:\t\t0.800562\n",
      "  validation loss:\t\t0.892035\n",
      "  validation accuracy:\t\t63.22 %\n",
      "Epoch 422 of 500 took 22.870s\n",
      "  training loss:\t\t0.801352\n",
      "  validation loss:\t\t0.902564\n",
      "  validation accuracy:\t\t62.80 %\n",
      "Epoch 423 of 500 took 20.513s\n",
      "  training loss:\t\t0.804193\n",
      "  validation loss:\t\t0.892799\n",
      "  validation accuracy:\t\t63.22 %\n",
      "Epoch 424 of 500 took 20.709s\n",
      "  training loss:\t\t0.799773\n",
      "  validation loss:\t\t0.897543\n",
      "  validation accuracy:\t\t63.28 %\n",
      "Epoch 425 of 500 took 20.673s\n",
      "  training loss:\t\t0.801386\n",
      "  validation loss:\t\t0.894385\n",
      "  validation accuracy:\t\t63.21 %\n",
      "Epoch 426 of 500 took 18.898s\n",
      "  training loss:\t\t0.800162\n",
      "  validation loss:\t\t0.893964\n",
      "  validation accuracy:\t\t62.88 %\n",
      "Epoch 427 of 500 took 20.259s\n",
      "  training loss:\t\t0.803013\n",
      "  validation loss:\t\t0.907083\n",
      "  validation accuracy:\t\t62.44 %\n",
      "Epoch 428 of 500 took 21.485s\n",
      "  training loss:\t\t0.800145\n",
      "  validation loss:\t\t0.904576\n",
      "  validation accuracy:\t\t62.80 %\n",
      "Epoch 429 of 500 took 22.215s\n",
      "  training loss:\t\t0.799253\n",
      "  validation loss:\t\t0.894801\n",
      "  validation accuracy:\t\t63.62 %\n",
      "Epoch 430 of 500 took 22.573s\n",
      "  training loss:\t\t0.800638\n",
      "  validation loss:\t\t0.895152\n",
      "  validation accuracy:\t\t63.10 %\n",
      "Epoch 431 of 500 took 21.893s\n",
      "  training loss:\t\t0.800934\n",
      "  validation loss:\t\t0.886781\n",
      "  validation accuracy:\t\t63.52 %\n",
      "Epoch 432 of 500 took 22.828s\n",
      "  training loss:\t\t0.799414\n",
      "  validation loss:\t\t0.905795\n",
      "  validation accuracy:\t\t62.52 %\n",
      "Epoch 433 of 500 took 23.239s\n",
      "  training loss:\t\t0.798933\n",
      "  validation loss:\t\t0.895812\n",
      "  validation accuracy:\t\t63.26 %\n",
      "Epoch 434 of 500 took 23.082s\n",
      "  training loss:\t\t0.796731\n",
      "  validation loss:\t\t0.887491\n",
      "  validation accuracy:\t\t63.79 %\n",
      "Epoch 435 of 500 took 23.152s\n",
      "  training loss:\t\t0.799883\n",
      "  validation loss:\t\t0.897490\n",
      "  validation accuracy:\t\t63.05 %\n",
      "Epoch 436 of 500 took 19.457s\n",
      "  training loss:\t\t0.796713\n",
      "  validation loss:\t\t0.894526\n",
      "  validation accuracy:\t\t62.97 %\n",
      "Epoch 437 of 500 took 17.310s\n",
      "  training loss:\t\t0.799493\n",
      "  validation loss:\t\t0.898310\n",
      "  validation accuracy:\t\t63.09 %\n",
      "Epoch 438 of 500 took 14.790s\n",
      "  training loss:\t\t0.797584\n",
      "  validation loss:\t\t0.896722\n",
      "  validation accuracy:\t\t62.87 %\n",
      "Epoch 439 of 500 took 20.533s\n",
      "  training loss:\t\t0.797832\n",
      "  validation loss:\t\t0.899258\n",
      "  validation accuracy:\t\t62.99 %\n",
      "Epoch 440 of 500 took 22.563s\n",
      "  training loss:\t\t0.796498\n",
      "  validation loss:\t\t0.902548\n",
      "  validation accuracy:\t\t62.82 %\n",
      "Epoch 441 of 500 took 22.344s\n",
      "  training loss:\t\t0.796912\n",
      "  validation loss:\t\t0.898472\n",
      "  validation accuracy:\t\t62.67 %\n",
      "Epoch 442 of 500 took 22.990s\n",
      "  training loss:\t\t0.797537\n",
      "  validation loss:\t\t0.895116\n",
      "  validation accuracy:\t\t62.95 %\n",
      "Epoch 443 of 500 took 22.898s\n",
      "  training loss:\t\t0.796098\n",
      "  validation loss:\t\t0.890374\n",
      "  validation accuracy:\t\t63.42 %\n",
      "Epoch 444 of 500 took 22.989s\n",
      "  training loss:\t\t0.796401\n",
      "  validation loss:\t\t0.900321\n",
      "  validation accuracy:\t\t62.99 %\n",
      "Epoch 445 of 500 took 16.218s\n",
      "  training loss:\t\t0.796597\n",
      "  validation loss:\t\t0.891930\n",
      "  validation accuracy:\t\t63.62 %\n",
      "Epoch 446 of 500 took 21.018s\n",
      "  training loss:\t\t0.798488\n",
      "  validation loss:\t\t0.896340\n",
      "  validation accuracy:\t\t63.44 %\n",
      "Epoch 447 of 500 took 21.273s\n",
      "  training loss:\t\t0.797101\n",
      "  validation loss:\t\t0.894852\n",
      "  validation accuracy:\t\t63.13 %\n",
      "Epoch 448 of 500 took 21.129s\n",
      "  training loss:\t\t0.795470\n",
      "  validation loss:\t\t0.901876\n",
      "  validation accuracy:\t\t63.06 %\n",
      "Epoch 449 of 500 took 22.307s\n",
      "  training loss:\t\t0.794231\n",
      "  validation loss:\t\t0.896345\n",
      "  validation accuracy:\t\t63.25 %\n",
      "Epoch 450 of 500 took 22.271s\n",
      "  training loss:\t\t0.796542\n",
      "  validation loss:\t\t0.898867\n",
      "  validation accuracy:\t\t63.12 %\n",
      "Epoch 451 of 500 took 22.056s\n",
      "  training loss:\t\t0.795727\n",
      "  validation loss:\t\t0.897222\n",
      "  validation accuracy:\t\t63.43 %\n",
      "Epoch 452 of 500 took 21.763s\n",
      "  training loss:\t\t0.792528\n",
      "  validation loss:\t\t0.904366\n",
      "  validation accuracy:\t\t63.07 %\n",
      "Epoch 453 of 500 took 21.108s\n",
      "  training loss:\t\t0.794475\n",
      "  validation loss:\t\t0.900777\n",
      "  validation accuracy:\t\t62.90 %\n",
      "Epoch 454 of 500 took 22.033s\n",
      "  training loss:\t\t0.792286\n",
      "  validation loss:\t\t0.903557\n",
      "  validation accuracy:\t\t62.56 %\n",
      "Epoch 455 of 500 took 22.579s\n",
      "  training loss:\t\t0.791970\n",
      "  validation loss:\t\t0.912391\n",
      "  validation accuracy:\t\t62.70 %\n",
      "Epoch 456 of 500 took 21.521s\n",
      "  training loss:\t\t0.792159\n",
      "  validation loss:\t\t0.888638\n",
      "  validation accuracy:\t\t63.54 %\n",
      "Epoch 457 of 500 took 22.787s\n",
      "  training loss:\t\t0.790638\n",
      "  validation loss:\t\t0.898361\n",
      "  validation accuracy:\t\t63.20 %\n",
      "Epoch 458 of 500 took 18.326s\n",
      "  training loss:\t\t0.792897\n",
      "  validation loss:\t\t0.895274\n",
      "  validation accuracy:\t\t63.04 %\n",
      "Epoch 459 of 500 took 13.872s\n",
      "  training loss:\t\t0.793034\n",
      "  validation loss:\t\t0.894229\n",
      "  validation accuracy:\t\t63.45 %\n",
      "Epoch 460 of 500 took 17.364s\n",
      "  training loss:\t\t0.792003\n",
      "  validation loss:\t\t0.895882\n",
      "  validation accuracy:\t\t63.04 %\n",
      "Epoch 461 of 500 took 14.441s\n",
      "  training loss:\t\t0.790828\n",
      "  validation loss:\t\t0.916594\n",
      "  validation accuracy:\t\t62.27 %\n",
      "Epoch 462 of 500 took 22.305s\n",
      "  training loss:\t\t0.791861\n",
      "  validation loss:\t\t0.904535\n",
      "  validation accuracy:\t\t62.78 %\n",
      "Epoch 463 of 500 took 22.004s\n",
      "  training loss:\t\t0.790038\n",
      "  validation loss:\t\t0.914451\n",
      "  validation accuracy:\t\t62.19 %\n",
      "Epoch 464 of 500 took 23.133s\n",
      "  training loss:\t\t0.791068\n",
      "  validation loss:\t\t0.904007\n",
      "  validation accuracy:\t\t62.91 %\n",
      "Epoch 465 of 500 took 22.450s\n",
      "  training loss:\t\t0.791522\n",
      "  validation loss:\t\t0.901398\n",
      "  validation accuracy:\t\t62.86 %\n",
      "Epoch 466 of 500 took 21.581s\n",
      "  training loss:\t\t0.792404\n",
      "  validation loss:\t\t0.893843\n",
      "  validation accuracy:\t\t63.42 %\n",
      "Epoch 467 of 500 took 20.459s\n",
      "  training loss:\t\t0.790749\n",
      "  validation loss:\t\t0.902273\n",
      "  validation accuracy:\t\t62.22 %\n",
      "Epoch 468 of 500 took 19.393s\n",
      "  training loss:\t\t0.788778\n",
      "  validation loss:\t\t0.898901\n",
      "  validation accuracy:\t\t63.08 %\n",
      "Epoch 469 of 500 took 14.325s\n",
      "  training loss:\t\t0.790138\n",
      "  validation loss:\t\t0.893937\n",
      "  validation accuracy:\t\t63.59 %\n",
      "Epoch 470 of 500 took 14.224s\n",
      "  training loss:\t\t0.788161\n",
      "  validation loss:\t\t0.890968\n",
      "  validation accuracy:\t\t63.28 %\n",
      "Epoch 471 of 500 took 17.719s\n",
      "  training loss:\t\t0.787110\n",
      "  validation loss:\t\t0.887954\n",
      "  validation accuracy:\t\t63.50 %\n",
      "Epoch 472 of 500 took 23.265s\n",
      "  training loss:\t\t0.787621\n",
      "  validation loss:\t\t0.912037\n",
      "  validation accuracy:\t\t62.46 %\n",
      "Epoch 473 of 500 took 23.224s\n",
      "  training loss:\t\t0.792241\n",
      "  validation loss:\t\t0.899056\n",
      "  validation accuracy:\t\t62.99 %\n",
      "Epoch 474 of 500 took 18.558s\n",
      "  training loss:\t\t0.787365\n",
      "  validation loss:\t\t0.891453\n",
      "  validation accuracy:\t\t63.27 %\n",
      "Epoch 475 of 500 took 18.081s\n",
      "  training loss:\t\t0.787683\n",
      "  validation loss:\t\t0.906469\n",
      "  validation accuracy:\t\t62.64 %\n",
      "Epoch 476 of 500 took 17.967s\n",
      "  training loss:\t\t0.788274\n",
      "  validation loss:\t\t0.890665\n",
      "  validation accuracy:\t\t63.93 %\n",
      "Epoch 477 of 500 took 13.810s\n",
      "  training loss:\t\t0.789279\n",
      "  validation loss:\t\t0.905731\n",
      "  validation accuracy:\t\t62.39 %\n",
      "Epoch 478 of 500 took 16.166s\n",
      "  training loss:\t\t0.787144\n",
      "  validation loss:\t\t0.914104\n",
      "  validation accuracy:\t\t62.12 %\n",
      "Epoch 479 of 500 took 16.138s\n",
      "  training loss:\t\t0.786966\n",
      "  validation loss:\t\t0.891248\n",
      "  validation accuracy:\t\t63.21 %\n",
      "Epoch 480 of 500 took 14.761s\n",
      "  training loss:\t\t0.785414\n",
      "  validation loss:\t\t0.898866\n",
      "  validation accuracy:\t\t63.27 %\n",
      "Epoch 481 of 500 took 14.967s\n",
      "  training loss:\t\t0.787182\n",
      "  validation loss:\t\t0.895747\n",
      "  validation accuracy:\t\t62.97 %\n",
      "Epoch 482 of 500 took 15.229s\n",
      "  training loss:\t\t0.785558\n",
      "  validation loss:\t\t0.911190\n",
      "  validation accuracy:\t\t63.00 %\n",
      "Epoch 483 of 500 took 18.407s\n",
      "  training loss:\t\t0.785153\n",
      "  validation loss:\t\t0.894022\n",
      "  validation accuracy:\t\t63.49 %\n",
      "Epoch 484 of 500 took 20.168s\n",
      "  training loss:\t\t0.783647\n",
      "  validation loss:\t\t0.897874\n",
      "  validation accuracy:\t\t63.20 %\n",
      "Epoch 485 of 500 took 21.331s\n",
      "  training loss:\t\t0.784435\n",
      "  validation loss:\t\t0.902554\n",
      "  validation accuracy:\t\t62.98 %\n",
      "Epoch 486 of 500 took 23.585s\n",
      "  training loss:\t\t0.786549\n",
      "  validation loss:\t\t0.889172\n",
      "  validation accuracy:\t\t63.87 %\n",
      "Epoch 487 of 500 took 23.249s\n",
      "  training loss:\t\t0.784217\n",
      "  validation loss:\t\t0.902397\n",
      "  validation accuracy:\t\t62.78 %\n",
      "Epoch 488 of 500 took 16.503s\n",
      "  training loss:\t\t0.784663\n",
      "  validation loss:\t\t0.883928\n",
      "  validation accuracy:\t\t63.85 %\n",
      "Epoch 489 of 500 took 14.754s\n",
      "  training loss:\t\t0.781494\n",
      "  validation loss:\t\t0.892323\n",
      "  validation accuracy:\t\t63.51 %\n",
      "Epoch 490 of 500 took 13.968s\n",
      "  training loss:\t\t0.785348\n",
      "  validation loss:\t\t0.903224\n",
      "  validation accuracy:\t\t62.67 %\n",
      "Epoch 491 of 500 took 13.883s\n",
      "  training loss:\t\t0.785155\n",
      "  validation loss:\t\t0.903453\n",
      "  validation accuracy:\t\t63.48 %\n",
      "Epoch 492 of 500 took 14.709s\n",
      "  training loss:\t\t0.783118\n",
      "  validation loss:\t\t0.897787\n",
      "  validation accuracy:\t\t63.42 %\n",
      "Epoch 493 of 500 took 17.571s\n",
      "  training loss:\t\t0.782926\n",
      "  validation loss:\t\t0.901518\n",
      "  validation accuracy:\t\t63.08 %\n",
      "Epoch 494 of 500 took 13.261s\n",
      "  training loss:\t\t0.787919\n",
      "  validation loss:\t\t0.886085\n",
      "  validation accuracy:\t\t63.65 %\n",
      "Epoch 495 of 500 took 13.172s\n",
      "  training loss:\t\t0.783031\n",
      "  validation loss:\t\t0.901532\n",
      "  validation accuracy:\t\t63.08 %\n",
      "Epoch 496 of 500 took 13.202s\n",
      "  training loss:\t\t0.784016\n",
      "  validation loss:\t\t0.903619\n",
      "  validation accuracy:\t\t62.94 %\n",
      "Epoch 497 of 500 took 13.618s\n",
      "  training loss:\t\t0.781604\n",
      "  validation loss:\t\t0.893892\n",
      "  validation accuracy:\t\t63.45 %\n",
      "Epoch 498 of 500 took 14.230s\n",
      "  training loss:\t\t0.783156\n",
      "  validation loss:\t\t0.909481\n",
      "  validation accuracy:\t\t62.63 %\n",
      "Epoch 499 of 500 took 13.565s\n",
      "  training loss:\t\t0.781295\n",
      "  validation loss:\t\t0.893879\n",
      "  validation accuracy:\t\t63.36 %\n",
      "Epoch 500 of 500 took 13.316s\n",
      "  training loss:\t\t0.781792\n",
      "  validation loss:\t\t0.900516\n",
      "  validation accuracy:\t\t63.01 %\n",
      "Final results:\n",
      "  test loss:\t\t\t0.899694\n",
      "  test accuracy:\t\t63.44 %\n"
     ]
    }
   ],
   "source": [
    "model='mlp'\n",
    "num_epochs=500\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading data...\")\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "y_val = y_val.astype(np.int32)\n",
    "\n",
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.matrix('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "# Create neural network model (depending on first command line parameter)\n",
    "print(\"Building model and compiling functions...\")\n",
    "network = build_mlp(input_var)\n",
    "\n",
    "# Create a loss expression for training, i.e., a scalar objective we want\n",
    "# to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()\n",
    "# We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "# Create update expressions for training, i.e., how to modify the\n",
    "# parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "# Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "        loss, params, learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# Create a loss expression for validation/testing. The crucial difference\n",
    "# here is that we do a deterministic forward pass through the network,\n",
    "# disabling dropout layers.\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                        target_var)\n",
    "\n",
    "test_loss = test_loss.mean()\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "\n",
    "# Compile a function performing a training step on a mini-batch (by giving\n",
    "# the updates dictionary) and returning the corresponding training loss:\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc], allow_input_downcast=True)\n",
    "\n",
    "pred_fn = theano.function([input_var], test_prediction)\n",
    "\n",
    "# Finally, launch the training loop.\n",
    "print(\"Starting training...\")\n",
    "# We iterate over epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, 500, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        a = train_fn(inputs, targets) #a is the loss\n",
    "        train_err += a\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, 500, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))\n",
    "\n",
    "# After training, we compute and print the test error:\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500, shuffle=False):\n",
    "    inputs, targets = batch\n",
    "    err, acc = val_fn(inputs, targets)\n",
    "    test_err += err\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "# Optionally, you could now dump the network weights to a file like this:\n",
    "np.savez('model2.npz', *lasagne.layers.get_all_param_values(network))\n",
    "#\n",
    "# And load them again later on like this:\n",
    "# with np.load('model.npz') as f:\n",
    "#     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "# lasagne.layers.set_all_param_values(network, param_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
