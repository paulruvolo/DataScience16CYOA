{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.stats as st\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from patsy import dmatrix, dmatrices\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_dir = os.path.dirname('__file__')\n",
    "\n",
    "train = pd.read_csv(os.path.join(cur_dir, \"data\", \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(cur_dir, \"data\", \"test.csv\"))\n",
    "mapdata = np.loadtxt(os.path.join(cur_dir, \"data\", \"sf_map.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_subset(df, n=None):\n",
    "    if (n is None):\n",
    "        return df\n",
    "    sub = random.sample(xrange(len(df)), min(n, len(df)))\n",
    "    return df.iloc[sub]\n",
    "\n",
    "def preprocess(df):\n",
    "    res = df.copy()\n",
    "    res = res[res.X != res.X.max()]\n",
    "    datetimes = res.Dates.apply(get_datetime)\n",
    "    res['Hour'] = datetimes.apply(lambda dt: dt.hour)\n",
    "    res['Month'] = datetimes.apply(lambda dt: dt.month)\n",
    "    res['Hour_Minutes'] = datetimes.apply(lambda dt: dt.hour + dt.minute / 60.0)\n",
    "    res['Minutes_Since_03'] = datetimes.apply(lambda dt: (dt-datetime(2003, 1, 1)).total_seconds() / 60)\n",
    "    res['Minutes_Since_New_Year'] = datetimes.apply(lambda dt: (dt-datetime(dt.year, 1, 1)).total_seconds() / 60)\n",
    "    res['DOW'] = train.DayOfWeek.apply(lambda x: dow.index(x))\n",
    "    res['Street_Corner'] = res['Address'].apply(lambda x: 1 if '/' in x else 0)\n",
    "    return res\n",
    "\n",
    "def get_datetime(s):\n",
    "    dt = datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return dt\n",
    "\n",
    "dow = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "def isNight(hour):\n",
    "    if hour in [0, 1, 2, 3, 4, 5, 6, 19, 20, 21, 22, 23]:\n",
    "        return \"Night\"\n",
    "    else:\n",
    "        return \"Day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = preprocess(get_random_subset(train))\n",
    "# train_df = preprocess(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_models(models, x_train, y_train):\n",
    "    for m in models:\n",
    "        m.fit(x_train, y_train)\n",
    "        \n",
    "def get_x_y_matrices(df, formula, target):\n",
    "    \n",
    "    x_vals = dmatrix(formula, data=df, return_type='dataframe')\n",
    "    y_vals = df[target]\n",
    "\n",
    "    return filter_infrequent(x_vals, y_vals)\n",
    "    \n",
    "def filter_infrequent(x, y, threshold=3):\n",
    "    counts = y.value_counts()\n",
    "    for cat, count in counts.iteritems():\n",
    "        if count < 3:\n",
    "            x = x[y != cat]\n",
    "            y = y[y != cat]\n",
    "            \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Weighted_Averager(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, models, weights):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "        self.probas = [len(models)]\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        for m in self.models:\n",
    "            m.fit(x, y)\n",
    "            \n",
    "    def predict_probas_cv(self, x, y):\n",
    "        probas = [None] * len(self.models)\n",
    "        for i, m in enumerate(self.models):\n",
    "            probas[i] = cross_val_predict(m, x, y)\n",
    "        self.probas = probas\n",
    "            \n",
    "    def calc_log_loss(self, y, weights=None):\n",
    "        if (weights is None):\n",
    "            weights = self.weights\n",
    "        res = None\n",
    "        for p, w in zip(self.probas, weights):\n",
    "            if res is None:\n",
    "                res = w * p\n",
    "            else:\n",
    "                res += w * p\n",
    "        return log_loss(y, res)\n",
    "            \n",
    "    def predict_proba(self, x):\n",
    "        res = None\n",
    "        for m, w in zip(self.models, self.weights):\n",
    "            if res is None:\n",
    "                res = w * m.predict_proba(x)\n",
    "            else:\n",
    "                res += w * m.predict_proba(x)\n",
    "                \n",
    "        return res\n",
    "    \n",
    "class ProbaRandomForestClassifier(RandomForestClassifier):\n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X)\n",
    "        \n",
    "class ProbaLogisticRegression(LogisticRegression):\n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "formula_ml = 'C(DayOfWeek) + C(PdDistrict) + Street_Corner + X+Y+Hour+Month'\n",
    "\n",
    "x_vals, y_vals = get_x_y_matrices(train_df, formula_ml, 'Category')\n",
    "\n",
    "clf_forest = ProbaRandomForestClassifier(min_samples_leaf=300)\n",
    "clf_logistic = ProbaLogisticRegression()\n",
    "\n",
    "# train_models([clf_forest, clf_logistic], X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_a = Weighted_Averager([clf_forest, clf_logistic], [0.5, 0.5])\n",
    "w_a.predict_probas_cv(x_vals, y_vals)\n",
    "weights = np.linspace(0.1, 0.9, 9)\n",
    "scores = []\n",
    "for w in weights:\n",
    "    s = w_a.calc_log_loss(y_vals, weights=[w, 1-w])\n",
    "    scores.append(s)\n",
    "    \n",
    "plt.plot(weights, scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
