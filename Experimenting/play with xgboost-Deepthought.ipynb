{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sophia and Mac-I\n",
    "\n",
    "This notebook is a notebook with tuned parameters to run on deepthought. Unsurprisingly, a boost in computational power also leads to a boost in model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports imported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.patches import Polygon\n",
    "# from matplotlib.collections import PatchCollection\n",
    "# from matplotlib import cm\n",
    "from datetime import datetime\n",
    "from ipywidgets import widgets  \n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "print \"imports imported\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data and Recoding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crimeData = pd.read_csv('train.csv')\n",
    "Categories = ['ARSON', 'ASSAULT', 'BAD CHECKS', 'BRIBERY', 'BURGLARY',\n",
    "              'DISORDERLY CONDUCT', 'DRIVING UNDER THE INFLUENCE',\n",
    "              'DRUG/NARCOTIC', 'DRUNKENNESS', 'EMBEZZLEMENT', 'EXTORTION',\n",
    "              'FAMILY OFFENSES', 'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING',\n",
    "              'KIDNAPPING', 'LARCENY/THEFT', 'LIQUOR LAWS', 'LOITERING',\n",
    "              'MISSING PERSON', 'NON-CRIMINAL', 'OTHER OFFENSES',\n",
    "              'PORNOGRAPHY/OBSCENE MAT', 'PROSTITUTION', 'RECOVERED VEHICLE',\n",
    "              'ROBBERY', 'RUNAWAY', 'SECONDARY CODES', 'SEX OFFENSES FORCIBLE',\n",
    "              'SEX OFFENSES NON FORCIBLE', 'STOLEN PROPERTY', 'SUICIDE',\n",
    "              'SUSPICIOUS OCC', 'TREA', 'TRESPASS', 'VANDALISM', 'VEHICLE THEFT',\n",
    "              'WARRANTS', 'WEAPON LAWS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodeData(df, isTrain = False):\n",
    "    '''This function takes in the dataframe that we get from loading in the \n",
    "    SF crime data and returns a re-coded dataframe that has all the \n",
    "    additional features we want to add and the categorical features recoded \n",
    "    and cleaned.\n",
    "    '''\n",
    "\n",
    "    #since the modifications are done in-place we don't return the dataframe. \n",
    "    #we do, however, return the list of all the columns we added.\n",
    "    df, newLatLon = removeOutlierLatLon(df)\n",
    "    df, newDate = recodeDates(df)\n",
    "    df, newDistrict = recodePoliceDistricts(df)\n",
    "    df, newWeather = addWeather(df)\n",
    "    print \"recoding addresses\"\n",
    "    df, newAddress, streetColumns = recodeAddresses(df)\n",
    "\n",
    "    \n",
    "    addedColumns = [] \n",
    "    addedColumns += newDate\n",
    "    addedColumns += newDistrict \n",
    "    addedColumns += newLatLon\n",
    "    addedColumns += newWeather\n",
    "    addedColumns += newAddress\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    if (isTrain):\n",
    "        newCategory = recodeCategories(df)\n",
    "        addedColumns += newCategory\n",
    "        try: #prevents error if the coumns have already been removed or we are processing test data\n",
    "            columnsToDrop = ['Descript', 'Resolution']\n",
    "            df.drop(columnsToDrop, axis=1, inplace=True)\n",
    "        except:\n",
    "            print \"already recoded or using test data\"\n",
    "         \n",
    "\n",
    "    return df, addedColumns, streetColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodeDates(df):\n",
    "    '''This function takes in a dataframe and recodes the date field into \n",
    "    useable values. Here, we also recode the day of week.'''\n",
    "    #Recode the dates column to year, month, day and hour columns\n",
    "    df['DateTime'] = df['Dates'].apply(\n",
    "        lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    df['Year'] = df['DateTime'].apply(lambda x: x.year)\n",
    "    df['Month'] = df['DateTime'].apply(lambda x: x.month)\n",
    "    df['Day'] = df['DateTime'].apply(lambda x: x.day)\n",
    "    df['Hour'] = df['DateTime'].apply(lambda x: x.hour)\n",
    "    df['Minute'] = df['DateTime'].apply(lambda x: x.minute)\n",
    "    df['DayOfWeekRecode'] = df['DateTime'].apply(lambda x: x.weekday())\n",
    "    df['MinuteOfWeek'] = df['DateTime'].apply(lambda x: x.weekday()*24*60 + x.hour*60 + x.minute)\n",
    "\n",
    "    return df, ['Year', 'Month', 'Day', 'Hour', 'Minute', 'DayOfWeekRecode','MinuteOfWeek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodePoliceDistricts(df):\n",
    "    '''This function recodes the police district to a one-hot encoding \n",
    "    scheme.'''\n",
    "    districts = df['PdDistrict'].unique().tolist()\n",
    "    newColumns = []\n",
    "    for district in districts:\n",
    "        newColumns.append('District' + district)\n",
    "        df['District' + district] = df['PdDistrict'].apply(\n",
    "            lambda x: int(x == district))\n",
    "\n",
    "    return df, newColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodeAddresses(df):\n",
    "    '''This function will attempt to create some features related to the address field in the database. To do this, \n",
    "    first, we need to split up the address field into two different address fields'''\n",
    "    \n",
    "    #If there are two addresss, split fields. Also extract the block number\n",
    "    df['Address1'] = df['Address'].apply(lambda x: re.sub(r'^\\d+ Block of ','',x.split(\" / \")[0]))\n",
    "    df['Address2'] = df['Address'].apply(lambda x: (x.split(\" / \")[1]) if (len(x.split(\" / \")) > 1) else '')\n",
    "    \n",
    "    streets = set(df['Address1'].unique().tolist() + df['Address2'].unique().tolist())\n",
    "    \n",
    "    streetColumns = []\n",
    "    i = 0\n",
    "    \n",
    "    print \"starting address dummy creation\"\n",
    "    \n",
    "    #address1Dummy = pd.get_dummies(df['Address1']).rename(columns=lambda x: str(x))\n",
    "    address1Dummy = pd.get_dummies(df['Address1'])\n",
    "    address1Dummy = address1Dummy.replace(0, np.nan)\n",
    "    \n",
    "    print \"completed address 1 dummy creation\"\n",
    "    address2Dummy = pd.get_dummies(df['Address2'])\n",
    "    address2Dummy = address2Dummy.replace(0, np.nan)\n",
    "    \n",
    "    print \"completed address 2 dummy creation\"\n",
    "    \n",
    "#     print address1Dummy\n",
    "#     print address2Dummy.info()\n",
    "    \n",
    "    mergedAddressDummy = address1Dummy.combine_first(address2Dummy)\n",
    "    \n",
    "    print \"completed address dummy DataFrames merge\"\n",
    "    mergedAddressDummy = mergedAddressDummy.fillna(0)\n",
    "    print \"completed fillna on mergedAddressDummy\"\n",
    "    \n",
    "    streetColumns = list(mergedAddressDummy.columns.values)\n",
    "    \n",
    "    df = pd.concat([df, mergedAddressDummy], axis=1)\n",
    "    print \"completed merge of original df and new dummy variable df\"\n",
    "    \n",
    "    print \"Dummy creation finished\"\n",
    "    \n",
    "#     for street in streets:\n",
    "#         df['OnStreet' + street] = df.apply(lambda x: (x['Address1'] == street or x['Address2'] == street), axis=1)\n",
    "#         streetColumns.append('OnStreet' + street)\n",
    "#         i += 1\n",
    "#         print i\n",
    "        \n",
    "\n",
    "    \n",
    "    df['BlockNumber'] = df['Address'].apply(lambda x: int(re.findall(r'^\\d+',x)[0]) if (len(re.findall(r'^\\d+',x)) > 0) else None )\n",
    "    df['BlockNumber'] = df['BlockNumber'].fillna(-1)\n",
    "    \n",
    "    #Also add the \"did the crime occur on a street corner field?\"\n",
    "    df['StreetCornerFlag'] = df['Address'].apply(lambda x: len(x.split(\" / \")) > 1)\n",
    "    \n",
    "    return df, ['StreetCornerFlag', 'BlockNumber'], streetColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeOutlierLatLon(df):\n",
    "    '''This function will attempt remove outlier Latitudes and Longitudes'''\n",
    "    df.loc[df.X > -121, 'X'] = df.loc[(df.X > -121)].apply(lambda row: df.X[df[\"PdDistrict\"] == row['PdDistrict']].median(), axis=1)\n",
    "    df.loc[df.Y > 38, 'Y'] = df.loc[(df.Y > 38)].apply(lambda row: df.Y[df[\"PdDistrict\"] == row['PdDistrict']].median(), axis=1)\n",
    "\n",
    "    return df, ['X', 'Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addWeather(df):\n",
    "    df['DATE'] = df['DateTime'].apply(lambda x: int( str(x.year)+x.strftime('%m')+x.strftime('%d') ))\n",
    "    \n",
    "    weatherData = pd.read_csv('weather1.csv')\n",
    "    weatherData = weatherData.replace('-9999', np.nan)\n",
    "    \n",
    "    weatherData = weatherData[['DATE','PRCP','TMAX','TMIN']]\n",
    "    \n",
    "    df = pd.merge(df, weatherData, on='DATE')\n",
    "    \n",
    "    return df, ['PRCP','TMAX','TMIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recodeCategories(df):\n",
    "    '''This function will attempt remove outlier Latitudes and Longitudes'''\n",
    "    #if 'Category' in df.columns:\n",
    "    df['CategoryRecode'] = df.Category.apply(lambda x: Categories.index(x))\n",
    "        \n",
    "    return df, ['CategoryRecode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recoding addresses\n",
      "starting address dummy creation\n",
      "completed address 1 dummy creation\n",
      "completed address 2 dummy creation\n",
      "completed address dummy DataFrames merge\n",
      "completed fillna on mergedAddressDummy\n",
      "completed merge of original df and new dummy variable df\n",
      "Dummy creation finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>DayOfWeekRecode</th>\n",
       "      <th>MinuteOfWeek</th>\n",
       "      <th>DistrictNORTHERN</th>\n",
       "      <th>...</th>\n",
       "      <th>YOUNG CT</th>\n",
       "      <th>YUKON ST</th>\n",
       "      <th>ZAMPA LN</th>\n",
       "      <th>ZENO PL</th>\n",
       "      <th>ZIRCON PL</th>\n",
       "      <th>ZOE ST</th>\n",
       "      <th>ZOO RD</th>\n",
       "      <th>BlockNumber</th>\n",
       "      <th>StreetCornerFlag</th>\n",
       "      <th>CategoryRecode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049.000000</td>\n",
       "      <td>878049</td>\n",
       "      <td>878049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-122.422763</td>\n",
       "      <td>37.767035</td>\n",
       "      <td>2008.712046</td>\n",
       "      <td>6.436509</td>\n",
       "      <td>15.570623</td>\n",
       "      <td>13.412655</td>\n",
       "      <td>20.155026</td>\n",
       "      <td>2.992691</td>\n",
       "      <td>5134.388787</td>\n",
       "      <td>0.119920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>704.776747</td>\n",
       "      <td>0.2970381</td>\n",
       "      <td>19.338687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025284</td>\n",
       "      <td>0.024165</td>\n",
       "      <td>3.631194</td>\n",
       "      <td>3.428972</td>\n",
       "      <td>8.783005</td>\n",
       "      <td>6.549573</td>\n",
       "      <td>18.594915</td>\n",
       "      <td>1.972023</td>\n",
       "      <td>2858.378361</td>\n",
       "      <td>0.324869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.009545</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>1001.193208</td>\n",
       "      <td>0.4569537</td>\n",
       "      <td>10.688637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-122.513642</td>\n",
       "      <td>37.707879</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-122.432952</td>\n",
       "      <td>37.752427</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2600.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-122.416420</td>\n",
       "      <td>37.775421</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5220.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-122.406959</td>\n",
       "      <td>37.784368</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7606.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-122.364937</td>\n",
       "      <td>37.819975</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10079.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8300.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X              Y           Year          Month  \\\n",
       "count  878049.000000  878049.000000  878049.000000  878049.000000   \n",
       "mean     -122.422763      37.767035    2008.712046       6.436509   \n",
       "std         0.025284       0.024165       3.631194       3.428972   \n",
       "min      -122.513642      37.707879    2003.000000       1.000000   \n",
       "25%      -122.432952      37.752427    2006.000000       3.000000   \n",
       "50%      -122.416420      37.775421    2009.000000       6.000000   \n",
       "75%      -122.406959      37.784368    2012.000000       9.000000   \n",
       "max      -122.364937      37.819975    2015.000000      12.000000   \n",
       "\n",
       "                 Day           Hour         Minute  DayOfWeekRecode  \\\n",
       "count  878049.000000  878049.000000  878049.000000    878049.000000   \n",
       "mean       15.570623      13.412655      20.155026         2.992691   \n",
       "std         8.783005       6.549573      18.594915         1.972023   \n",
       "min         1.000000       0.000000       0.000000         0.000000   \n",
       "25%         8.000000       9.000000       0.000000         1.000000   \n",
       "50%        16.000000      14.000000      19.000000         3.000000   \n",
       "75%        23.000000      19.000000      33.000000         5.000000   \n",
       "max        31.000000      23.000000      59.000000         6.000000   \n",
       "\n",
       "        MinuteOfWeek  DistrictNORTHERN       ...             YOUNG CT  \\\n",
       "count  878049.000000     878049.000000       ...        878049.000000   \n",
       "mean     5134.388787          0.119920       ...             0.000026   \n",
       "std      2858.378361          0.324869       ...             0.005118   \n",
       "min         1.000000          0.000000       ...             0.000000   \n",
       "25%      2600.000000          0.000000       ...             0.000000   \n",
       "50%      5220.000000          0.000000       ...             0.000000   \n",
       "75%      7606.000000          0.000000       ...             0.000000   \n",
       "max     10079.000000          1.000000       ...             1.000000   \n",
       "\n",
       "            YUKON ST       ZAMPA LN        ZENO PL      ZIRCON PL  \\\n",
       "count  878049.000000  878049.000000  878049.000000  878049.000000   \n",
       "mean        0.000026       0.000018       0.000005       0.000015   \n",
       "std         0.005118       0.004269       0.002134       0.003848   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              ZOE ST         ZOO RD    BlockNumber  StreetCornerFlag  \\\n",
       "count  878049.000000  878049.000000  878049.000000            878049   \n",
       "mean        0.000091       0.000114     704.776747         0.2970381   \n",
       "std         0.009545       0.010671    1001.193208         0.4569537   \n",
       "min         0.000000       0.000000      -1.000000             False   \n",
       "25%         0.000000       0.000000       0.000000                 0   \n",
       "50%         0.000000       0.000000     300.000000                 0   \n",
       "75%         0.000000       0.000000    1000.000000                 1   \n",
       "max         1.000000       1.000000    8300.000000              True   \n",
       "\n",
       "       CategoryRecode  \n",
       "count   878049.000000  \n",
       "mean        19.338687  \n",
       "std         10.688637  \n",
       "min          0.000000  \n",
       "25%         16.000000  \n",
       "50%         20.000000  \n",
       "75%         25.000000  \n",
       "max         38.000000  \n",
       "\n",
       "[8 rows x 2105 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crimeData, addedColumns, streetColumns = recodeData(\n",
    "    crimeData, isTrain = True)\n",
    "crimeData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepping for training complete\n"
     ]
    }
   ],
   "source": [
    "columnsToUse = addedColumns\n",
    "\n",
    "commonStreets = ['FOLSOM ST','16TH ST','JONES ST','TAYLOR ST',\n",
    "                 'ARMSTRONG AV','EDDY ST','LARKIN ST','CASTRO ST',\n",
    "                 '10TH AV','5TH ST','HAIGHT ST','OFARRELL ST',\n",
    "                 '11TH AV','PAGE ST','FITCH ST','CAPP ST','13TH ST',\n",
    "                 '24TH AV','17TH ST','18TH ST','19TH ST','GENEVA AV',\n",
    "                 'GEARY BL','BRYANT ST','HYDE ST','4TH ST','FULTON ST',\n",
    "                 'LEAVENWORTH ST','COLE ST','ALEMANY BL','PHELPS ST',\n",
    "                 'MISSION ST','6TH ST','12TH AV','SHOTWELL ST',\n",
    "                 'TREAT AV','7TH ST','JEFFERSON ST','QUESADA AV',\n",
    "                 'TURK ST','2ND ST','MARKET ST','GGBRIDGE HY',\n",
    "                 '24TH ST','CAPITOL AV','KEARNY ST','HARRISON ST',\n",
    "                 'LYON ST','BUSH ST','POLK ST','3RD ST','ELLIS ST',\n",
    "                 'SOUTH VAN NESS AV','POTRERO AV','20TH ST','POWELL ST']\n",
    "\n",
    "columnsToUse = ['X','Y', 'Year', 'Month', 'Day','Hour', 'Minute',\n",
    "       'DayOfWeekRecode', 'DistrictNORTHERN', 'DistrictPARK',\n",
    "       'DistrictINGLESIDE', 'DistrictBAYVIEW', 'DistrictRICHMOND',\n",
    "       'DistrictCENTRAL', 'DistrictTARAVAL', 'DistrictTENDERLOIN',\n",
    "       'DistrictMISSION', 'DistrictSOUTHERN', 'StreetCornerFlag', 'PRCP','TMAX','TMIN']\n",
    "\n",
    "# columnsToUse = ['X','Y', 'Year', 'Month', 'Day','Hour', 'Minute',\n",
    "#        'DayOfWeekRecode', 'StreetCornerFlag']\n",
    "\n",
    "X = crimeData[columnsToUse]\n",
    "y = crimeData['CategoryRecode']\n",
    "\n",
    "print \"prepping for training complete\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've created a function that takes in a classifier and how many splits to do, and runs a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runOnTrainData(clf, numSplits=1):\n",
    "    \n",
    "    k_folds = StratifiedShuffleSplit(y, numSplits, test_size=0.5, random_state=0)\n",
    "\n",
    "    scores = []\n",
    "    print \"starting kfold testing\"\n",
    "\n",
    "    for k, (train, test) in enumerate(k_folds):\n",
    "        print \"starting fit\"\n",
    "        start = time()\n",
    "        clf.fit(X.iloc[train], y.iloc[train], eval_metric = 'mlogloss', verbose=3)\n",
    "        print \"fit complete, time: \" + str((time() - start))\n",
    "        startPredictTime = time()\n",
    "        probs = clf.predict_proba(X.iloc[test])\n",
    "        print \"predict complete, time: \" + str((time() - startPredictTime))\n",
    "        score = log_loss(y.iloc[test].values, probs)\n",
    "        print score\n",
    "        print \"total time: \" + str((time() - start))\n",
    "        scores.append(score)\n",
    "\n",
    "    print(scores)\n",
    "    print(\"Average: \" + str(np.average(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(max_depth=8, n_estimators=800, objective='multi:softprob', max_delta_step = .8, learning_rate = .0375, nthread = -1)\n",
    "runOnTrainData(clf, numSplits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictorsUsed = ['DistrictBAYVIEW',\n",
    " 'Y',\n",
    " 'Hour',\n",
    " 'DistrictSOUTHERN',\n",
    " 'DistrictTARAVAL',\n",
    " 'DistrictRICHMOND',\n",
    " 'Month',\n",
    " 'DistrictTENDERLOIN',\n",
    " 'DistrictNORTHERN',\n",
    " 'DayOfWeekRecode',\n",
    " 'Minute',\n",
    " 'Year',\n",
    " 'StreetCornerFlag',\n",
    " 'X',\n",
    " 'DistrictPARK',\n",
    " 'DistrictMISSION',\n",
    " 'Day',\n",
    " 'DistrictCENTRAL',\n",
    " 'DistrictINGLESIDE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a submission file, we modified the submission function from [this script](https://www.kaggle.com/shifanmao/sf-crime/random-forest-2/code). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission(clf, Xtrain, ytrain, predictors, path='my_submissionXGBoostWithWeather.csv'):\n",
    "    '''This function will take in a trained model, a list of predictors, and an optional \n",
    "    filepath and create a submissision file for us.'''\n",
    "   \n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    print \"test data loaded\"\n",
    "    \n",
    "    test_data, newColumns, streetColumns = recodeData(test_data)\n",
    "    print \"test data recoded\"\n",
    "    \n",
    "    testDataColumns = list(test_data.columns.values)\n",
    "    \n",
    "    existingPredictors = list(set(predictors) & set(testDataColumns))\n",
    "    \n",
    "    clf.fit(Xtrain[existingPredictors], ytrain, eval_metric = 'mlogloss')\n",
    "    print \"model fitted with all data\"\n",
    "    \n",
    "    #clf.fit(trainX[predictors], trainY)\n",
    "    predictions = clf.predict_proba(test_data[existingPredictors])\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'Id': test_data.Id\n",
    "    })\n",
    "    \n",
    "    for i in range(predictions.shape[1]):\n",
    "        submission[Categories[i]] = predictions[:,i]\n",
    "    submission.to_csv(path, index=False)\n",
    "\n",
    "    print(\" -- Wrote submission to file {}.\".format(path))\n",
    "    return existingPredictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictorsUsed = make_submission(clf, X, y, columnsToUse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've created a function to report the best scores from our classifier, doing a grid search on parameters to learn on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=10):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "clfOpt = xgb.XGBClassifier(objective='multi:softprob', nthread = 12, max_delta_step = 1)\n",
    "#(max_depth=7, n_estimators=100, objective='multi:softprob', max_delta_step = 1, learning_rate = .33)\n",
    "\n",
    "param_dist = {\"max_depth\": [5, 7, 9],\n",
    "              \"n_estimators\": [500, 1000],\n",
    "              \"learning_rate\": [0.033, .1]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clfOpt, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, scoring=\"log_loss\", verbose=3, cv=1)\n",
    "\n",
    "finalX = X[predictorsUsed].values.astype(np.float32)\n",
    "finaly = y.values.astype(int)\n",
    "\n",
    "print \"pre Random search finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"starting Randomized Search\"\n",
    "start = time()\n",
    "random_search.fit(finalX, finaly)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We explored using grid search to find a good set of parameters for our model. We found this useful, and found that the number of estimates should be about 30 times the learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
