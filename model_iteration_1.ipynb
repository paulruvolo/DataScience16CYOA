{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 1\n",
    "### SF-Crime Kaggle Challenge      2.23.16\n",
    "##### Data Science 2016 - CYOA Project.\n",
    "_______________________________________________________\n",
    "\n",
    "##### Olin College\n",
    "##### David Abrahams & Brenna Manning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.stats as st\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur_dir = os.path.dirname('__file__')\n",
    "\n",
    "train = pd.read_csv(os.path.join(cur_dir, \"data\", \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(cur_dir, \"data\", \"test.csv\"))\n",
    "mapdata = np.loadtxt(os.path.join(cur_dir, \"data\", \"sf_map.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_subset(df, n=5000):\n",
    "    sub = random.sample(xrange(len(df)), min(n, len(df)))\n",
    "    return df.iloc[sub]\n",
    "\n",
    "def preprocess(df):\n",
    "    res = df.copy()\n",
    "    res = res[res.X != res.X.max()]\n",
    "    datetimes = res.Dates.apply(get_datetime)\n",
    "    res['Hour'] = datetimes.apply(lambda dt: dt.hour)\n",
    "    res['Month'] = datetimes.apply(lambda dt: dt.month)\n",
    "    res['Hour_Minutes'] = datetimes.apply(lambda dt: dt.hour + dt.minute / 60.0)\n",
    "    res['Minutes_Since_03'] = datetimes.apply(lambda dt: (dt-datetime(2003, 1, 1)).total_seconds() / 60)\n",
    "    res['Minutes_Since_New_Year'] = datetimes.apply(lambda dt: (dt-datetime(dt.year, 1, 1)).total_seconds() / 60)\n",
    "    res['DOW'] = train.DayOfWeek.apply(lambda x: dow.index(x))\n",
    "    res['Street_Corner'] = res['Address'].apply(lambda x: 1 if '/' in x else 0)\n",
    "    return res\n",
    "\n",
    "def get_datetime(s):\n",
    "    dt = datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return dt\n",
    "\n",
    "dow = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "def isNight(hour):\n",
    "    if hour in [0, 1, 2, 3, 4, 5, 6, 19, 20, 21, 22, 23]:\n",
    "        return \"Night\"\n",
    "    else:\n",
    "        return \"Day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = preprocess(get_random_subset(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "View the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 X            Y         Hour        Month  Hour_Minutes  \\\n",
      "count  4999.000000  4999.000000  4999.000000  4999.000000   4999.000000   \n",
      "mean   -122.423268    37.767410    13.395279     6.425485     13.727372   \n",
      "std       0.025634     0.024204     6.575643     3.406617      6.589602   \n",
      "min    -122.513642    37.707922     0.000000     1.000000      0.016667   \n",
      "25%    -122.433911    37.753007     9.000000     4.000000      9.500000   \n",
      "50%    -122.416491    37.775421    14.000000     6.000000     14.500000   \n",
      "75%    -122.407246    37.784422    19.000000     9.000000     19.000000   \n",
      "max    -122.365565    37.819975    23.000000    12.000000     23.983333   \n",
      "\n",
      "       Minutes_Since_03  Minutes_Since_New_Year          DOW  Street_Corner  \n",
      "count       4999.000000             4999.000000  4999.000000    4999.000000  \n",
      "mean     3258941.313863           258826.186837     3.013203       0.298060  \n",
      "std      1918458.993609           150295.264468     1.953600       0.457452  \n",
      "min         7320.000000                1.000000     0.000000       0.000000  \n",
      "25%      1552849.500000           130727.500000     1.000000       0.000000  \n",
      "50%      3264000.000000           255660.000000     3.000000       0.000000  \n",
      "75%      4973075.000000           384840.500000     5.000000       1.000000  \n",
      "max      6502594.000000           525540.000000     6.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "print train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: \n",
      "0.15925902435\n",
      "0.161399772597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from patsy import dmatrix\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "training, validation = train_test_split(train_df, train_size=.60)\n",
    "\n",
    "formula_ml = 'X+Y'\n",
    "x_train = dmatrix(formula_ml, data=train_df, return_type='dataframe')\n",
    "#print x_train\n",
    "# print y_train\n",
    "#y_train = np.asarray(y_train).ravel()\n",
    "\n",
    "alg = RandomForestClassifier()\n",
    "# print y_train.shape\n",
    "# # print x_train.shape\n",
    "# scores1 = cross_validation.cross_val_score(alg, x_train, train_df['Category'], cv=3)\n",
    "# scores2 = cross_validation.cross_val_score(alg, train_df[['X', 'Y']], train_df['Category'], cv=3)\n",
    "alg.fit()\n",
    "\n",
    "print 'Score: '\n",
    "print str(scores1.mean())\n",
    "print str(scores2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Notes on this Notebook:\n",
    "\n",
    "#### Did not appear to score well by accuracy - need to score using log-loss for Kaggle Challenge.\n",
    "#### Will explore algorithm more in depth and revise scoring in next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
